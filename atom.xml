<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zfylin-非鱼</title>
  <subtitle>子非鱼焉知鱼之乐</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-02-20T06:32:50.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>zfylin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java集合类</title>
    <link href="http://yoursite.com/2017/02/20/JAVA%20synchronized%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2017/02/20/JAVA synchronized 详解/</id>
    <published>2017-02-20T02:23:48.000Z</published>
    <updated>2017-02-20T06:32:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Java语言的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。</p>
<ol>
<li>当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块；</li>
<li>当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块；</li>
<li>尤其关键的是，当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞；</li>
<li>第三个例子同样适用其它同步代码块。也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其它线程对该object对象所有同步代码部分的访问都被暂时阻塞；</li>
<li>以上规则对其它对象锁同样适用。<h1 id="例子代码"><a href="#例子代码" class="headerlink" title="例子代码"></a>例子代码</h1></li>
</ol>
<ul>
<li><strong>当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。</strong><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Thread1</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" - synchronized loop "</span> + i);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        Thread1 t1 = <span class="keyword">new</span> Thread1();</div><div class="line">        Thread ta = <span class="keyword">new</span> Thread(t1, <span class="string">"A"</span>);</div><div class="line">        Thread tb = <span class="keyword">new</span> Thread(t1, <span class="string">"B"</span>);</div><div class="line">        ta.start();</div><div class="line">        tb.start();</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">结果：</div><div class="line">A - synchronized loop 0</div><div class="line">A - synchronized loop 1</div><div class="line">A - synchronized loop 2</div><div class="line">A - synchronized loop 3</div><div class="line">A - synchronized loop 4</div><div class="line">B - synchronized loop 0</div><div class="line">B - synchronized loop 1</div><div class="line">B - synchronized loop 2</div><div class="line">B - synchronized loop 3</div><div class="line">B - synchronized loop 4</div></pre></td></tr></table></figure>
<ul>
<li><p><strong>当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该object中的非synchronized(this)同步代码块。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Thread2</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">m4t1</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</div><div class="line">            <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">            <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" : "</span> + i);</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">        <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">            System.out.println(Thread.currentThread().getName() + <span class="string">" : "</span> + i);</div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line">                TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                e.printStackTrace();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">final</span> Thread2 myt2 = <span class="keyword">new</span> Thread2();</div><div class="line">        Thread t1 = <span class="keyword">new</span> Thread(myt2::m4t1, <span class="string">"t1"</span>);</div><div class="line">        Thread t2 = <span class="keyword">new</span> Thread(myt2::m4t2, <span class="string">"t2"</span>);</div><div class="line">        t1.start();</div><div class="line">        t2.start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有其它synchronized(this)同步代码块的访问将被阻塞。</strong> </p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">// 修改Thread2.m4t2()方法：</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">()</span> </span>&#123;</div><div class="line">      <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">      <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</div><div class="line">          <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">              System.out.println(Thread.currentThread().getName() + <span class="string">" : "</span> + i);</div><div class="line">              <span class="keyword">try</span> &#123;</div><div class="line">                  TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">              &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                  e.printStackTrace();</div><div class="line">              &#125;</div><div class="line">          &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">结果：</div><div class="line">t1 : 4</div><div class="line">t1 : 3</div><div class="line">t1 : 2</div><div class="line">t1 : 1</div><div class="line">t1 : 0</div><div class="line">t2 : 4</div><div class="line">t2 : 3</div><div class="line">t2 : 2</div><div class="line">t2 : 1</div><div class="line">t2 : 0</div></pre></td></tr></table></figure>
<ul>
<li>第三个例子也可以用synchronized方法来实现。<strong>也就是说，当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。</strong>结果，其它线程对该object对象所有同步代码部分的访问都被暂时阻塞。（方法m4t2xx的synchronized关键字可以在public后，也可以在public前）<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">//修改Thread2.m4t2()方法如下：</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">    <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">        System.out.println(Thread.currentThread().getName() + <span class="string">" : "</span> + i);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            Thread.sleep(<span class="number">500</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">结果：</div><div class="line">t1 : 4</div><div class="line">t1 : 3</div><div class="line">t1 : 2</div><div class="line">t1 : 1</div><div class="line">t1 : 0</div><div class="line">t2 : 4</div><div class="line">t2 : 3</div><div class="line">t2 : 2</div><div class="line">t2 : 1</div><div class="line">t2 : 0</div></pre></td></tr></table></figure>
<ul>
<li>以上规则对其它对象锁同样适用<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Thread3</span> </span>&#123;</div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Inner</span> </span>&#123;</div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">m4t1</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">            <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" : Inner.m4t1()="</span> + i);</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">()</span> </span>&#123;</div><div class="line">            <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">            <span class="keyword">while</span> (i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">                System.out.println(Thread.currentThread().getName() + <span class="string">" : Inner.m4t2()="</span> + i);</div><div class="line">                <span class="keyword">try</span> &#123;</div><div class="line">                    TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">                    e.printStackTrace();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">m4t1</span><span class="params">(Inner inner)</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (inner) &#123; <span class="comment">//使用对象锁</span></div><div class="line">            inner.m4t1();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">(Inner inner)</span> </span>&#123;</div><div class="line">        inner.m4t2();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="keyword">final</span> Thread3 myt3 = <span class="keyword">new</span> Thread3();</div><div class="line">        <span class="keyword">final</span> Inner inner = myt3.new Inner();</div><div class="line">        Thread t1 = <span class="keyword">new</span> Thread(() -&gt; myt3.m4t1(inner), <span class="string">"t1"</span>);</div><div class="line">        Thread t2 = <span class="keyword">new</span> Thread(() -&gt; myt3.m4t2(inner), <span class="string">"t2"</span>);</div><div class="line">        t1.start();</div><div class="line">        t2.start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">结果：</div><div class="line">t1 : Inner.m4t1()=4</div><div class="line">t2 : Inner.m4t2()=4</div><div class="line">t2 : Inner.m4t2()=3</div><div class="line">t1 : Inner.m4t1()=3</div><div class="line">t2 : Inner.m4t2()=2</div><div class="line">t1 : Inner.m4t1()=2</div><div class="line">t2 : Inner.m4t2()=1</div><div class="line">t1 : Inner.m4t1()=1</div><div class="line">t2 : Inner.m4t2()=0</div><div class="line">t1 : Inner.m4t1()=0</div></pre></td></tr></table></figure>
<p>尽管线程t1获得了对Inner的对象锁，但由于线程t2访问的是同一个Inner中的非同步部分。所以两个线程互不干扰。<br><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">// 现在在Inner.m4t2()前面加上synchronized：</span></div><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">m4t2</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> i = <span class="number">5</span>;</div><div class="line">    <span class="keyword">while</span>(i-- &gt; <span class="number">0</span>) &#123;</div><div class="line">        System.out.println(Thread.currentThread().getName() + <span class="string">" : Inner.m4t2()="</span> + i);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            TimeUnit.SECONDS.sleep(<span class="number">1</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">结果:</div><div class="line">t1 : Inner.m4t1()=4</div><div class="line">t1 : Inner.m4t1()=3</div><div class="line">t1 : Inner.m4t1()=2</div><div class="line">t1 : Inner.m4t1()=1</div><div class="line">t1 : Inner.m4t1()=0</div><div class="line">t2 : Inner.m4t2()=4</div><div class="line">t2 : Inner.m4t2()=3</div><div class="line">t2 : Inner.m4t2()=2</div><div class="line">t2 : Inner.m4t2()=1</div><div class="line">t2 : Inner.m4t2()=0</div></pre></td></tr></table></figure>
<p>尽管线程t1与t2访问了同一个Inner对象中两个毫不相关的部分,但因为t1先获得了对Inner的对象锁，所以t2对Inner.m4t2()的访问也被阻塞，因为m4t2()是Inner中的一个同步方法。</p>
<h1 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h1><p>synchronized 关键字，它包括两种用法：synchronized 方法和 synchronized 块。  </p>
<ul>
<li>synchronized 方法：通过在方法声明中加入 synchronized关键字来声明 synchronized 方法。 </li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">accessVal</span><span class="params">(<span class="keyword">int</span> newVal)</span></span>;</div></pre></td></tr></table></figure>
<p>synchronized 方法控制对类成员变量的访问：每个类实例对应一把锁，每个 synchronized 方法都必须获得调用该方法的类实例的锁方能执行，否则所属线程阻塞，方法一旦执行，就独占该锁，直到从该方法返回时才将锁释放，此后被阻塞的线程方能获得该锁，重新进入可执行状态。这种机制确保了同一时刻对于每一个类实例，其所有声明为 synchronized 的成员函数中至多只有一个处于可执行状态（因为至多只有一个能够获得该类实例对应的锁），从而有效避免了类成员变量的访问冲突（只要所有可能访问类成员变量的方法均被声明为 synchronized）</p>
<ul>
<li>synchronized 块：通过 synchronized关键字来声明synchronized 块。<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">synchronized</span>(syncObject) &#123;  </div><div class="line"><span class="comment">//允许访问控制的代码  </span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>synchronized 块是这样一个代码块，其中的代码必须获得对象 syncObject （如前所述，可以是类实例或类）的锁方能执行，具体机制同前所述。由于可以针对任意代码块，且可任意指定上锁的对象，故灵活性较高。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>总的说来，synchronized关键字可以作为函数的修饰符，也可作为函数内的语句，也就是平时说的同步方法和同步语句块。如果再细的分类，<br>synchronized可作用于instance变量、object reference（对象引用）、static函数和class literals(类名称字面常量)身上。<br>我们需要明确几点：</p>
<ol>
<li><strong>无论synchronized关键字加在方法上还是对象上，它取得的锁都是对象，而不是把一段代码或函数当作锁――而且同步方法很可能还会被其他线程的对象访问</strong>；</li>
<li><strong>每个对象只有一个锁（lock）与之相关联</strong>；</li>
<li><strong>实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制</strong>。</li>
</ol>
<p>假设P1、P2是同一个类的不同对象，这个类中定义了以下几种情况的同步块或同步方法，P1、P2就都可以调用它们。</p>
<ul>
<li>把synchronized当作函数修饰符时，示例代码如下：<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">methodAAA</span><span class="params">()</span></span></div><div class="line">&#123;</div><div class="line">    <span class="comment">//….</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>这也就是同步方法，那这时synchronized锁定的是哪个对象呢？它锁定的是调用这个同步方法对象。也就是说，当一个对象P1在不同的线程中执行这个同步方法时，它们之间会形成互斥，达到同步的效果。但是这个对象所属的Class所产生的另一对象P2却可以任意调用这个被加了synchronized关键字的方法。<br>上边的示例代码等同于如下代码：<br><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodAAA</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>)      <span class="comment">// (1)</span></div><div class="line">    &#123;</div><div class="line">        <span class="comment">//…..</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>(1)处的this指的是什么呢？它指的就是调用这个方法的对象，如P1。<strong>可见同步方法实质是将synchronized作用于object reference</strong>。那个拿到了P1对象锁的线程，才可以调用P1的同步方法，而对P2而言，P1这个锁与它毫不相干，程序也可能在这种情形下摆脱同步机制的控制，造成数据混乱。</p>
<ul>
<li>同步块，示例代码如下：<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">method3</span><span class="params">(SomeObject so)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">synchronized</span> (so)</div><div class="line">    &#123;</div><div class="line">        <span class="comment">//….. </span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>这时，锁就是so这个对象，谁拿到这个锁谁就可以运行它所控制的那段代码。当有一个明确的对象作为锁时，就可以这样写程序，但当没有明确的对象作为锁，只是想让一段代码同步时，可以创建一个特殊的instance变量（它得是一个对象）来充当锁：<br><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] lock = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>]; <span class="comment">// 特殊的instance变量</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodA</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (lock) &#123;</div><div class="line">            <span class="comment">//…</span></div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//…..</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>注：零长度的byte数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而Object lock =  new Object()则需要7行操作码</strong>。</p>
<ul>
<li>将synchronized作用于static 函数，示例代码如下：<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Foo</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">methodAAA</span><span class="params">()</span>   <span class="comment">// 同步的static 函数</span></span></div><div class="line">    &#123;</div><div class="line">        <span class="comment">//….</span></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">methodBBB</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">synchronized</span> (Foo.class)   <span class="comment">// class literal(类名称字面常量)</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>代码中的methodBBB()方法是把class literal作为锁的情况，它和同步的static函数产生的效果是一样的，取得的锁很特别，是当前调用这个方法的对象所属的类（Class，而不再是由这个Class产生的某个具体对象了）。<br><strong><em>可以推断：如果一个类中定义了一个synchronized的static函数A，也定义了一个synchronized 的instance函数B，那么这个类的同一对象Obj在多线程中分别访问A和B两个方法时，不会构成同步，因为它们的锁都不一样。A方法的锁是Obj这个对象，而B的锁是Obj所属的那个Class。</em></strong><br>还有一些技巧可以让我们对共享资源的同步访问更加安全：</p>
<ol>
<li>定义private 的instance变量+它的 get方法，而不要定义public/protected的instance变量。如果将变量定义为public，对象在外界可以绕过同步方法的控制而直接取得它，并改动它。这也是JavaBean的标准实现方式之一。</li>
<li>如果instance变量是一个对象，如数组或ArrayList什么的，那上述方法仍然不安全，因为当外界对象通过get方法拿到这个instance对象的引用后，又将其指向另一个对象，那么这private变量也就变了，岂不是很危险。 这个时候就需要将get方法也加上synchronized同步，并且，只返回这个private对象的clone()――这样，调用端得到的就是对象副本的引用了。</li>
</ol>
<p>　</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;Java语言的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
    
    </summary>
    
      <category term="java并发" scheme="http://yoursite.com/categories/java%E5%B9%B6%E5%8F%91/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="并发" scheme="http://yoursite.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Java集合类</title>
    <link href="http://yoursite.com/2017/02/17/Java%E9%9B%86%E5%90%88%E7%B1%BB/"/>
    <id>http://yoursite.com/2017/02/17/Java集合类/</id>
    <published>2017-02-17T07:50:22.000Z</published>
    <updated>2017-02-17T08:30:10.626Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>集合类主要负责保存、盛装其他数据，因此集合类也被称为容器类。所以的集合类都位于java.util包下，后来为了处理多线程环境下的并发安全问题，java5还在java.util.concurrent包下提供了一些多线程支持的集合类。<br>Java容器类类库的用途是”保存对象”，并将其划分为两个不同的概念：</p>
<ul>
<li><strong>Collection</strong>：  一组”对立”的元素，通常这些元素都服从某种规则<ul>
<li><strong>List</strong> 必须保持元素特定的顺序</li>
<li><strong>Set</strong> 不能有重复元素</li>
<li><strong>Queue</strong> 保持一个队列(先进先出)的顺序</li>
</ul>
</li>
<li><strong>Map</strong>： 一组成对的”键值对”对象</li>
</ul>
<p>Collection和Map的区别在于容器中每个位置保存的元素个数:</p>
<ul>
<li>Collection 每个位置只能保存一个元素(对象)</li>
<li>Map保存的是”键值对”，就像一个小型数据库。我们可以通过”键”找到该键对应的”值”</li>
</ul>
<h1 id="架构层次关系"><a href="#架构层次关系" class="headerlink" title="架构层次关系"></a>架构层次关系</h1><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">java.util.Collection [I]</div><div class="line">+--java.util.List [I]</div><div class="line">   +--java.util.ArrayList [C]</div><div class="line">   +--java.util.LinkedList [C]</div><div class="line">   +--java.util.Vector [C]</div><div class="line">      +--java.util.Stack [C]</div><div class="line">+--java.util.Set [I]</div><div class="line">   +--java.util.HashSet [C]</div><div class="line">   +--java.util.SortedSet [I]</div><div class="line">      +--java.util.TreeSet [C]</div><div class="line"></div><div class="line">java.util.Map [I]</div><div class="line">+--java.util.SortedMap [I]</div><div class="line">   +--java.util.TreeMap [C]</div><div class="line">+--java.util.Hashtable [C]</div><div class="line">+--java.util.HashMap [C]</div><div class="line">+--java.util.LinkedHashMap [C]</div><div class="line">+--java.util.WeakHashMap [C]</div><div class="line"> </div><div class="line">[I]：接口</div><div class="line">[C]：类</div></pre></td></tr></table></figure>
<h2 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h2><p>Collection是最基本的集合接口，一个Collection代表一组Object的集合，这些Object被称作Collection的元素。<br>所有实现Collection接口的类都必须提供两个标准的构造函数：无参数的构造函数用于创建一个空的Collection，有一个Collection参数的构造函数用于创建一个新的Collection，这 个新的Collection与传入的Collection有相同的元素。后一个构造函数允许用户复制一个Collection。<br>如何遍历Collection中的每一个元素？不论Collection的实际类型如何，它都支持一个iterator()的方法，该方法返回一个迭代子，使用该迭代子即可逐一访问Collection中每一个元素。典型的用法如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Iterator it = collection.iterator(); // 获得一个迭代器</div><div class="line">while(it.hasNext()) &#123; </div><div class="line">　　Object obj = it.next(); // 得到下一个元素 </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><p>List继承自Collection接口。List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。<br>跟Set集合不同的是，List允许有重复元素。对于满足e1.equals(e2)条件的e1与e2对象元素，可以同时存在于List集合中。当然，也有List的实现类不允许重复元素的存在。<br>除了具有Collection接口必备的iterator()方法外，List还提供一个listIterator()方法，返回一个 ListIterator接口，和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素， 还能向前或向后遍历。<br>实现List接口的常用类有LinkedList，ArrayList，Vector和Stack。</p>
<h4 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h4><p>LinkedList实现了List接口，允许null元素。此外LinkedList提供额外的get，remove，insert方法在 LinkedList的首部或尾部。这些操作使LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。<br>注意LinkedList没有同步方法。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">List list = Collections.synchronizedList(new LinkedList(...));</div></pre></td></tr></table></figure></p>
<h4 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h4><p>ArrayList实现了可变大小的数组。它允许所有元素，包括null。ArrayList没有同步。<br>size，isEmpty，get，set方法运行时间为常数。但是add方法开销为分摊的常数，添加n个元素需要O(n)的时间。其他的方法运行时间为线性。<br>每个ArrayList实例都有一个容量（Capacity），即用于存储元素的数组的大小。这个容量可随着不断添加新元素而自动增加，但是增长算法并 没有定义。当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。<br>和LinkedList一样，ArrayList也是非同步的（unsynchronized）。</p>
<h4 id="Vector"><a href="#Vector" class="headerlink" title="Vector"></a>Vector</h4><p>vector非常类似ArrayList，但是Vector是同步的。由Vector创建的Iterator，虽然和ArrayList创建的 Iterator是同一接口，但是，因为Vector是同步的，当一个Iterator被创建而且正在被使用，另一个线程改变了Vector的状态（例如，添加或删除了一些元素），这时调用Iterator的方法时将抛出ConcurrentModificationException，因此必须捕获该异常。</p>
<h5 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h5><p>Stack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。</p>
<h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><p>Set继承自Collection接口。Set是一种不能包含有重复元素的集合，即对于满足e1.equals(e2)条件的e1与e2对象元素，不能同时存在于同一个Set集合里，换句话说，Set集合里任意两个元素e1和e2都满足e1.equals(e2)==false条件，Set最多有一个null元素。 因为Set的这个制约，在使用Set集合的时候，应该注意：</p>
<ul>
<li><strong>为Set集合里的元素的实现类实现一个有效的equals(Object)方法。</strong></li>
<li><strong>对Set的构造函数，传入的Collection参数不能包含重复的元素。</strong></li>
</ul>
<p><em>请注意：必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。</em></p>
<h4 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h4><p>此类实现 Set 接口，由哈希表（实际上是一个 HashMap 实例）支持。它不保证集合的迭代顺序；特别是它不保证该顺序恒久不变。此类允许使用 null 元素。<br>HashSet不是同步的，需要用以下语句来进行S同步转换：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">Set s = Collections.synchronizedSet(new HashSet(...));</div></pre></td></tr></table></figure></p>
<h3 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h3><p>Map没有继承Collection接口。也就是说Map和Collection是2种不同的集合。Collection可以看作是（value）的集合，而Map可以看作是（key，value）的集合。<br>Map接口由Map的内容提供3种类型的集合视图，一组key集合，一组value集合，或者一组key-value映射关系的集合。</p>
<h4 id="Hashtable"><a href="#Hashtable" class="headerlink" title="Hashtable"></a>Hashtable</h4><p>Hashtable继承Map接口，实现一个key-value映射的哈希表。任何非空（non-null）的对象都可作为key或者value。<br>添加数据使用put(key, value)，取出数据使用get(key)，这两个基本操作的时间开销为常数。<br>Hashtable 通过initial capacity和load factor两个参数调整性能。通常缺省的load factor 0.75较好地实现了时间和空间的均衡。增大load factor可以节省空间但相应的查找时间将增大，这会影响像get和put这样的操作。<br>由于作为key的对象将通过计算其散列函数来确定与之对应的value的位置，因此任何作为key的对象都必须实现hashCode和equals方 法。hashCode和equals方法继承自根类Object，如果你用自定义的类当作key的话，要相当小心，按照散列函数的定义，如果两个对象相 同，即obj1.equals(obj2)=true，则它们的hashCode必须相同，但如果两个对象不同，则它们的hashCode不一定不同，如 果两个不同对象的hashCode相同，这种现象称为冲突，冲突会导致操作哈希表的时间开销增大，所以尽量定义好的hashCode()方法，能加快哈希 表的操作。<br>如果相同的对象有不同的hashCode，对哈希表的操作会出现意想不到的结果（期待的get方法返回null），要避免这种问题，只需要牢记一条：<strong>要同时复写equals方法和hashCode方法，而不要只写其中一个。</strong><br>Hashtable是同步的。</p>
<h4 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h4><p>HashMap和Hashtable类似，不同之处在于HashMap是非同步的，并且允许null，即null value和null key。，但是将HashMap视为Collection时（values()方法可返回Collection），其迭代子操作时间开销和HashMap 的容量成比例。因此，如果迭代操作的性能相当重要的话，不要将HashMap的初始化容量设得过高，或者load factor过低。</p>
<h4 id="WeakHashMap"><a href="#WeakHashMap" class="headerlink" title="WeakHashMap"></a>WeakHashMap</h4><p>WeakHashMap是一种改进的HashMap，它对key实行“弱引用”，如果一个key不再被外部所引用，那么该key可以被GC回收。</p>
<h2 id="对集合操作的工具类"><a href="#对集合操作的工具类" class="headerlink" title="对集合操作的工具类"></a>对集合操作的工具类</h2><ul>
<li>Java提供了java.util.Collections，以及java.util.Arrays类简化对集合的操作。</li>
<li>java.util.Collections主要提供一些static方法用来操作或创建Collection，Map等集合。</li>
<li>java.util.Arrays主要提供static方法对数组进行操作。<h1 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h1></li>
<li>如果涉及到堆栈，队列等操作，应该考虑用List，对于需要快速插入，删除元素，应该使用LinkedList，如果需要快速随机访问元素，应该使用ArrayList。</li>
<li>如果程序在单线程环境中，或者访问仅仅在一个线程中进行，考虑非同步的类，其效率较高，如果多个线程可能同时操作一个类，应该使用同步的类。</li>
<li>在除需要排序时使用TreeSet,TreeMap外,都应使用HashSet,HashMap,因为他们 的效率更高。</li>
<li><strong>要特别注意对哈希表的操作，作为key的对象要正确复写equals和hashCode方法。</strong></li>
<li>容器类仅能持有对象引用（指向对象的指针），而不是将对象信息copy一份至数列某位置。一旦将对象置入容器内，便损失了该对象的型别信息。</li>
<li>尽量返回接口而非实际的类型，如返回List而非ArrayList，这样如果以后需要将ArrayList换成LinkedList时，客户端代码不用改变。这就是针对抽象编程。</li>
</ul>
<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><ol>
<li>Collection没有get()方法来取得某个元素。只能通过iterator()遍历元素。</li>
<li>Set和Collection拥有一模一样的接口。</li>
<li>List，可以通过get()方法来一次取出一个元素。使用数字来选择一堆对象中的一个，get(0)…。(add/get)</li>
<li>一般使用ArrayList。用LinkedList构造堆栈stack、队列queue。</li>
<li>Map用 put(k,v) / get(k)，还可以使用containsKey()/containsValue()来检查其中是否含有某个key/value。HashMap会利用对象的hashCode来快速找到key。</li>
<li>Map中元素，可以将key序列、value序列单独抽取出来。<ul>
<li>使用keySet()抽取key序列，将map中的所有keys生成一个Set。</li>
<li>使用values()抽取value序列，将map中的所有values生成一个Collection.</li>
<li>为什么一个生成Set，一个生成Collection？那是因为，key总是独一无二的，value允许重复。</li>
</ul>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;集合类主要负责保存、盛装其他数据，因此集合类也被称为容器类。所以的集合类都位于java.util包下，后来为了处理多线程环境
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="collection" scheme="http://yoursite.com/tags/collection/"/>
    
  </entry>
  
  <entry>
    <title>impala的原理架构</title>
    <link href="http://yoursite.com/2017/02/16/impala%E7%9A%84%E5%8E%9F%E7%90%86%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2017/02/16/impala的原理架构/</id>
    <published>2017-02-16T12:05:26.000Z</published>
    <updated>2017-02-17T02:10:12.314Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>由cloudera公司主导开发的大数据实时查询分析工具，宣称比原来基于MapReduce的HiveSQL查询速度提升3~90倍，且更加灵活易用。提供类SQL的查询语句，能够查询存储在Hadoop的HDFS和Hbase中的PB级大数据。查询速度快是其最大的卖点。简言之impala作为大数据实时查询分析工具，具有查询速度快，灵活性高，易整合，可伸缩性强等特点。</p>
<ol>
<li>查询速度快。Impala不同于Hive，hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程。不同于hive，impala中间结果不写入磁盘，即使及时通过网络以流的形式传递，大大降低的节点的IO开销。</li>
<li>灵活性高。可以直接查询存储在HDFS上的原生数据，也可以查询经过优化设计而存储的数据，只需要数据的格式能够兼容MapReduce、hive、Pig等等。</li>
<li>易整合。很容易和hadoop系统整合，并使用hadoop生态系统的资源和优势，不需要将数据迁移到特定的存储系统就能满足查询分析的要求。</li>
<li>可伸缩性。可以很好的与一些BI应用系统协同工作，如Microstrategy、Tableau、Qlikview等。</li>
</ol>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><center><img src="http://p1.bpimg.com/567571/e5d78868e694ffd2.jpg" alt=""></center><br>Impala没有再使用缓慢的Hive+MapReduce批处理，而是通过使用与商用并行关系数据库中类似的分布式查询引擎（由Query Planner、Query Coordinator和Query Exec Engine三部分组成），可以直接从HDFS或HBase中用SELECT、JOIN和统计函数查询数据，从而大大降低了延迟。<br>Impala主要由Impalad， State Store和CLI组成。<br>- <strong>Impalad</strong>: 与DataNode运行在同一节点上，由Impalad进程表示，它接收客户端的查询请求（接收查询请求的Impalad为Coordinator，Coordinator通过JNI调用java前端解释SQL查询语句，生成查询计划树，再通过调度器把执行计划分发给具有相应数据的其它Impalad进行执行），读写数据，并行执行查询，并把结果通过网络流式的传送回给Coordinator，由Coordinator返回给客户端。同时Impalad也与State Store保持连接，用于确定哪个Impalad是健康和可以接受新的工作。在Impalad中启动三个ThriftServer: beeswax_server（连接客户端），hs2_server（借用Hive元数据）， be_server（Impalad内部使用）和一个ImpalaServer服务。<br>- <strong>Impala State Store</strong>: 跟踪集群中的Impalad的健康状态及位置信息，由statestored进程表示，它通过创建多个线程来处理Impalad的注册订阅和与各Impalad保持心跳连接，各Impalad都会缓存一份State Store中的信息，当State Store离线后（Impalad发现State Store处于离线时，会进入recovery模式，反复注册，当State Store重新加入集群后，自动恢复正常，更新缓存数据）因为Impalad有State Store的缓存仍然可以工作，但会因为有些Impalad失效了，而已缓存数据无法更新，导致把执行计划分配给了失效的Impalad，导致查询失败。<br>- <strong>CLI</strong>: 提供给用户查询使用的命令行工具（Impala Shell使用python实现），同时Impala还提供了Hue，JDBC， ODBC使用接口。<br>上图可以看出，位于Datanode上的每个impalad进程，都具有Query Planner,QueryCoordinator,Query ExecEnginer这几个组件，每个impala节点在功能上是对等的，也就是说，任何一个节点都能接受外部查询请求。当有一个节点发生故障后，其他节点仍然能够接管，这还得益于HDFS的数据冗余备份机制，即使某个impalad节点挂掉，只要挂掉的节点上的数据在其他节点上有备份，仍然是可以计算的。<br><br># 查询处理过程<br><br><center><img src="http://i1.piimg.com/567571/3149d21b5be7b352.png" alt=""></center>

<h1 id="Impala-VS-Hive"><a href="#Impala-VS-Hive" class="headerlink" title="Impala VS Hive"></a>Impala VS Hive</h1><p> Impala与Hive都是构建在Hadoop之上的数据查询工具各有不同的侧重适应面，但从客户端使用来看Impala与Hive有很多的共同之处，如数据表元数据、ODBC/JDBC驱动、SQL语法、灵活的文件格式、存储资源池等。Impala与Hive在Hadoop中的关系如图 2所示。<strong>Hive适合于长时间的批处理查询分析，而Impala适合于实时交互式SQL查询</strong>。可以先使用hive进行数据转换处理，之后使用Impala在Hive处理后的结果数据集上进行快速的数据分析。</p>
<p><center><img src="http://p1.bpimg.com/567571/f027ca73464a765a.jpg" alt=""></center></p>
<h2 id="异同"><a href="#异同" class="headerlink" title="异同"></a>异同</h2><ul>
<li><strong>数据存储</strong>：使用相同的存储数据池都支持把数据存储于HDFS, HBase。</li>
<li><strong>元数据</strong>：两者使用相同的元数据。</li>
<li><strong>SQL解释处理</strong>：比较相似都是通过词法分析生成执行计划。</li>
<li><strong>执行计划</strong>：<ul>
<li>Hive:依赖于MapReduce执行框架，执行计划分成 map-&gt;shuffle-&gt;reduce-&gt;map-&gt;shuffle-&gt;reduce…的模型。如果一个Query会 被编译成多轮MapReduce，则会有更多的写中间结果。由于MapReduce执行框架本身的特点，过多的中间过程会增加整个Query的执行时间。</li>
<li>Impala:把执行计划表现为一棵完整的执行计划树，可以更自然地分发执行计划到各个Impalad执行查询，而不用像Hive那样把它组合成管道型的map-&gt;reduce模式，以此保证Impala有更好的并发性和避免不必要的中间sort与shuffle。</li>
</ul>
</li>
<li><strong>数据流</strong>：<ul>
<li>Hive:采用推的方式，每一个计算节点计算完成后将数据主动推给后续节点。</li>
<li>Impala:采用拉的方式，后续节点通过getNext主动向前面节点要数据，以此方式数据可以流式的返回给客户端，且只要有1条数据被处理完，就可以立即展现出来，而不用等到全部处理完成，更符合SQL交互式查询使用。</li>
</ul>
</li>
<li><strong>内存使用</strong>：<ul>
<li>Hive:在执行过程中如果内存放不下所有数据，则会使用外存，以保证Query能顺 序执行完。每一轮MapReduce结束，中间结果也会写入HDFS中，同样由于MapReduce执行架构的特性，shuffle过程也会有写本地磁盘的操作。</li>
<li>Impala:在遇到内存放不下数据时，当前版本1.0.1是直接返回错误，而不会利用外存，以后版本应该会进行改进。这使用得Impala目前处理Query会受到一定的限制，最好还是与Hive配合使用。Impala在多个阶段之间利用网络传输数据，在执行过程不会有写磁盘的操作（insert除外）。</li>
</ul>
</li>
<li><strong>调度</strong>：<ul>
<li>Hive:任务调度依赖于Hadoop的调度策略。</li>
<li>Impala:调度由自己完成，目前只有一种调度器simple-schedule，它会尽量满足数据的局部性，扫描数据的进程尽量靠近数据本身所在的物理机器。调度器目前还比较简单，在SimpleScheduler::GetBackend中可以看到，现在还没有考虑负载，网络IO状况等因素进行调度。但目前Impala已经有对执行过程的性能统计分析，应该以后版本会利用这些统计信息进行调度吧。</li>
</ul>
</li>
<li><strong>容错</strong>：<ul>
<li>Hive:依赖于Hadoop的容错能力。</li>
<li>Impala:在查询过程中，没有容错逻辑，如果在执行过程中发生故障，则直接返回错误（这与Impala的设计有关，因为Impala定位于实时查询，一次查询失败，再查一次就好了，再查一次的成本很低）。但从整体来看，Impala是能很好的容错，所有的Impalad是对等的结构，用户可以向任何一个 Impalad提交查询，如果一个Impalad失效，其上正在运行的所有Query都将失败，但用户可以重新提交查询由其它Impalad代替执行，不会影响服务。对于State Store目前只有一个，但当State Store失效，也不会影响服务，每个Impalad都缓存了State Store的信息，只是不能再更新集群状态，有可能会把执行任务分配给已经失效的Impalad执行，导致本次Query失败。</li>
</ul>
</li>
<li><strong>适用面</strong>：<ul>
<li>Hive:复杂的批处理查询任务，数据转换任务。</li>
<li>Impala：实时数据分析，因为不支持UDF，能处理的问题域有一定的限制，与Hive配合使用,对Hive的结果数据集进行实时分析。</li>
</ul>
</li>
</ul>
<h2 id="Impala相对于Hive的优化技术"><a href="#Impala相对于Hive的优化技术" class="headerlink" title="Impala相对于Hive的优化技术"></a>Impala相对于Hive的优化技术</h2><ul>
<li>没有使用 MapReduce进行并行计算，虽然MapReduce是非常好的并行计算框架，但它更多的面向批处理模式，而不是面向交互式的SQL执行。与MapReduce相比：Impala把整个查询分成一执行计划树，而不是一连串的MapReduce任务，在分发执行计划后，Impala使用拉式获取数据的方式获取结果，把结果数据组成按执行树流式传递汇集，减少的了把中间结果写入磁盘的步骤，再从磁盘读取数据的开销。Impala使用服务的方式避免每次执行查询都需要启动的开销，即相比Hive没了MapReduce启动时间。</li>
<li>使用LLVM产生运行代码，针对特定查询生成特定代码，同时使用Inline的方式减少函数调用的开销，加快执行效率。</li>
<li>充分利用可用的硬件指令（SSE4.2）。</li>
<li>更好的IO调度，Impala知道数据块所在的磁盘位置能够更好的利用多磁盘的优势，同时Impala支持直接数据块读取和本地代码计算checksum。</li>
<li>通过选择合适的数据存储格式可以得到最好的性能（Impala支持多种存储格式）。</li>
<li>最大使用内存，中间结果不写磁盘，及时通过网络以stream的方式传递。</li>
</ul>
<h1 id="Impala的优缺点"><a href="#Impala的优缺点" class="headerlink" title="Impala的优缺点"></a>Impala的优缺点</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>支持SQL查询，快速查询大数据。</li>
<li>可以对已有数据进行查询，减少数据的加载，转换。</li>
<li>多种存储格式可以选择（Parquet, Text, Avro, RCFile, SequeenceFile）。</li>
<li>可以与Hive配合使用。</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>不支持用户定义函数UDF。</li>
<li>不支持text域的全文搜索。</li>
<li>不支持Transforms。</li>
<li>不支持查询期的容错。</li>
<li>对内存要求高。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;由cloudera公司主导开发的大数据实时查询分析工具，宣称比原来基于MapReduce的HiveSQL查询速度提升3~90倍，且更加灵活易
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="impala" scheme="http://yoursite.com/tags/impala/"/>
    
  </entry>
  
  <entry>
    <title>Hbase原理、基本概念、基本架构</title>
    <link href="http://yoursite.com/2017/02/16/Hbase%E5%8E%9F%E7%90%86%E3%80%81%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E3%80%81%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/"/>
    <id>http://yoursite.com/2017/02/16/Hbase原理、基本概念、基本架构/</id>
    <published>2017-02-16T07:02:22.000Z</published>
    <updated>2017-02-17T02:10:12.147Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>HBase是一个构建在HDFS上的分布式列存储系统；<br>HBase是基于Google BigTable模型开发的，典型的key/value系统；<br>HBase是Apache Hadoop生态系统中的重要一员，主要用于海量结构化数据存储；<br>从逻辑上讲，HBase将数据按照表、行和列进行存储。<br>与hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。</p>
<h2 id="Hbase-表特点"><a href="#Hbase-表特点" class="headerlink" title="Hbase 表特点"></a>Hbase 表特点</h2><ul>
<li><strong>大</strong>：一个表可以有数十亿行，上百万列；</li>
<li><strong>无模式</strong>：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列；</li>
<li><strong>面向列</strong>：面向列（族）的存储和权限控制，列（族）独立检索；</li>
<li><strong>稀疏</strong>：空（null）列并不占用存储空间，表可以设计的非常稀疏；</li>
<li><strong>数据多版本</strong>：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳；</li>
<li><strong>数据类型单一</strong>：Hbase中的数据都是字符串，没有类型。</li>
</ul>
<h1 id="Hbase-数据模型"><a href="#Hbase-数据模型" class="headerlink" title="Hbase 数据模型"></a>Hbase 数据模型</h1><h2 id="Hbase-逻辑视图"><a href="#Hbase-逻辑视图" class="headerlink" title="Hbase 逻辑视图"></a>Hbase 逻辑视图</h2><center><img src="http://i1.piimg.com/567571/041186b6b6f7c6d5.jpg" alt=""></center><br>## Hbase 基本概念<br>- RowKey：是Byte array，是表中每条记录的“主键”，方便快速查找，Rowkey的设计非常重要。<br>- Column Family：列族，拥有一个名称(string)，包含一个或者多个相关列<br>- Column：属于某一个columnfamily，familyName:columnName，每条记录可动态添加<br>- Version Number：类型为Long，默认值是系统时间戳，可由用户自定义<br>- Value(Cell)：Byte array<br><br># Hbase 物理模型<br>每个column family存储在HDFS上的一个单独文件中，空值不会被保存。<br>Key 和 Version number在每个 column family中均有一份；<br>HBase 为每个值维护了多级索引，即：\<key, column="" family,="" name,="" timestamp\=""><br>## 物理存储<br>-  Table中所有行都按照row key的字典序排列；<br>-  Table在行的方向上分割为多个Region；<br>- Region按大小分割的，每个表开始只有一个Region，随着数据增多，Region不断增大，当增大到一个阀值的时候，Region就会等分会两个新的Region，之后会有越来越多的Region；<br>- Region是Hbase中分布式存储和负载均衡的最小单元，不同Region分布到不同RegionServer上;<br><center><img src="http://p1.bpimg.com/567571/f2b44b62778590fd.png" alt=""></center><br>- Region虽然是分布式存储的最小单元，但并不是存储的最小单元。Region由一个或者多个Store组成，每个store保存一个columns family；每个Strore又由一个memStore和0至多个StoreFile组成，StoreFile包含HFile；memStore存储在内存中，StoreFile存储在HDFS上。<br><center><img src="http://i1.piimg.com/567571/cef3cba296a41b07.png" alt=""></center>

<h1 id="Hbase-架构及基本组件"><a href="#Hbase-架构及基本组件" class="headerlink" title="Hbase 架构及基本组件"></a>Hbase 架构及基本组件</h1><p><center><img src="http://i1.piimg.com/567571/e5524df5446fab63.jpg" alt=""></center></p>
<h2 id="基本组件说明"><a href="#基本组件说明" class="headerlink" title="基本组件说明"></a>基本组件说明</h2><ul>
<li><strong>Client</strong>：包含访问HBase的接口，并维护cache来加快对HBase的访问，比如Region的位置信息</li>
<li><strong>Master</strong><ul>
<li>为Region server分配Region</li>
<li>负责Region server的负载均衡</li>
<li>发现失效的Region server并重新分配其上的Region</li>
<li>管理用户对table的增删改查操作</li>
</ul>
</li>
<li><strong>Region server</strong><ul>
<li>Regionserver维护Region，处理对这些Region的IO请求</li>
<li>Regionserver负责切分在运行过程中变得过大的region</li>
</ul>
</li>
<li><strong>Zookeeper</strong><ul>
<li>通过选举，保证任何时候，集群中只有一个master，Master与RegionServers 启动时会向ZooKeeper注册</li>
<li>存贮所有Region的寻址入口</li>
<li>实时监控Region server的上线和下线信息。并实时通知给Master</li>
<li>存储HBase的schema和table元数据</li>
<li>默认情况下，HBase 管理ZooKeeper 实例，比如， 启动或者停止ZooKeeper</li>
<li>Zookeeper的引入使得Master不再是单点故障</li>
</ul>
</li>
<li><strong>Write-Ahead-Log（WAL）</strong>(预写式日志)<br><center><img src="http://p1.bqimg.com/567571/daa136c290a5faf5.png" alt=""></center><br>该机制用于数据的容错和恢复：<br>每个HRegionServer中都有一个HLog对象，HLog是一个实现Write Ahead Log的类，在每次用户操作写入MemStore的同时，也会写一份数据到HLog文件中，HLog文件定期会滚动出新的，并删除旧的文件（已持久化到StoreFile中的数据）。当HRegionServer意外终止后，HMaster会通过Zookeeper感知到，HMaster首先会处理遗留的 HLog文件，将其中不同Region的Log数据进行拆分，分别放到相应region的目录下，然后再将失效的region重新分配，领取到这些region的HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。<h2 id="HBase容错性"><a href="#HBase容错性" class="headerlink" title="HBase容错性"></a>HBase容错性</h2></li>
<li>Master容错：Zookeeper重新选择一个新的Master<ul>
<li>无Master过程中，数据读取仍照常进行；</li>
<li>无master过程中，region切分、负载均衡等无法进行；</li>
</ul>
</li>
<li>RegionServer容错：定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳，Master将该RegionServer上的Region重新分配到其他RegionServer上，失效服务器上“预写”日志由主服务器进行分割并派送给新的RegionServer</li>
<li>Zookeeper容错：Zookeeper是一个可靠地服务，一般配置3或5个Zookeeper实例<h2 id="Region定位流程"><a href="#Region定位流程" class="headerlink" title="Region定位流程"></a>Region定位流程</h2><center><img src="http://i1.piimg.com/567571/bb229506635f0f77.jpg" alt=""></center></li>
<li>寻找RegionServer<br>ZooKeeper–&gt; -ROOT-(单Region)–&gt; .META.–&gt; 用户表</li>
<li>-ROOT-<ul>
<li>表包含.META.表所在的region列表，该表只会有一个Region；</li>
<li>Zookeeper中记录了-ROOT-表的location。</li>
</ul>
</li>
<li>.META.<br>表包含所有的用户空间region列表，以及RegionServer的服务器地址。</li>
</ul>
<h1 id="Hbase-使用场景"><a href="#Hbase-使用场景" class="headerlink" title="Hbase 使用场景"></a>Hbase 使用场景</h1><ul>
<li>大数据量存储，大数据量高并发操作</li>
<li>需要对数据随机读写操作</li>
<li>读写访问均是非常简单的操作</li>
</ul>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="http://wenku.baidu.com/view/b46eadd228ea81c758f578f4.html" target="_blank" rel="external">读和写的流程</a><br><a href="http://blog.csdn.net/dianacody/article/details/39530165" target="_blank" rel="external">HBase的Region机制</a></p>
</key,>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;HBase是一个构建在HDFS上的分布式列存储系统；&lt;br&gt;HBase是基于Google BigTable模型开发的，典型的key/valu
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="Hbase" scheme="http://yoursite.com/tags/Hbase/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>centos7 网桥的配置</title>
    <link href="http://yoursite.com/2017/01/06/centos7%20%E7%BD%91%E6%A1%A5%E7%9A%84%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2017/01/06/centos7 网桥的配置/</id>
    <published>2017-01-06T06:11:45.000Z</published>
    <updated>2017-02-17T02:10:12.231Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://tonylit.me/2016/04/06/centos7%E7%BD%91%E6%A1%A5%E9%85%8D%E7%BD%AE/" target="_blank" rel="external">http://tonylit.me/2016/04/06/centos7%E7%BD%91%E6%A1%A5%E9%85%8D%E7%BD%AE/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://tonylit.me/2016/04/06/centos7%E7%BD%91%E6%A1%A5%E9%85%8D%E7%BD%AE/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://tonylit.me/2016
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="centos" scheme="http://yoursite.com/tags/centos/"/>
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>hive &amp; hbase</title>
    <link href="http://yoursite.com/2016/12/30/hive%20&amp;%20hbase/"/>
    <id>http://yoursite.com/2016/12/30/hive &amp; hbase/</id>
    <published>2016-12-30T01:23:32.000Z</published>
    <updated>2017-02-17T02:10:12.307Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Hive 是为了简化编写MapReduce程序而生的</strong>，使用MapReduce做过数据分析的人都知道，很多分析程序除业务逻辑不同外，程序流程基本一样。在这种 情况下，就需要Hive这样的用戶编程接口。Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑，就是些表 的定义等，也就是表的元数据。使用SQL实现Hive是因为SQL大家都熟悉，转换成本低，类似作用的Pig就不是SQL。</p>
<p><strong>HBase为查询而生的</strong>，它通过组织起节点內所有机器的內存，提供一個超大的內存Hash表，它需要组织自己的数据结构，包括磁盘和內存中的，而Hive是不做这个的，表在HBase中是物理表，而不是逻辑表，搜索引擎使用它來存储索引，以满足查询的实时性需求。</p>
<p>hive类似CloudBase，也是基于hadoop分布式计算平台上的提供data warehouse的sql功能的一套软件。使得存储在hadoop里面的海量数据的汇总，即席查询简单化。hive提供了一套QL的查询语言，以sql为基础，使用起来很方便。</p>
<p><strong>HBase是一个分布式的基于列存储的非关系型数据库</strong>。HBase的查询效率很高，主要由于查询和展示结果。</p>
<p><strong>hive 是分布式的关系型数据库</strong>。主要用来并行分布式处理大量数据。hive中的所有查询除了”select <em> from table;”都是需要通过Map\Reduce的方式来执行的。由于要走Map\Reduce，即使一个只有1行1列的表，如果不是通过select </em> from table;方式来查询的，可能也需要8、9秒。但hive比较擅长处理大量数据。当要处理的数据很多，并且Hadoop集群有足够的规模，这时就能体现 出它的优势。<br><em>通过hive的存储接口，hive和Hbase可以整合使用。</em></p>
<ol>
<li>hive是sql语言，通过数据库的方式来操作hdfs文件系统，为了简化编程，底层计算方式为mapreduce。</li>
<li>hive是面向行存储的数据库。</li>
<li>Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。</li>
<li>HBase为查询而生的，它通过组织起节点內所有机器的內存，提供一個超大的內存Hash表</li>
<li>hbase不是关系型数据库，而是一个在hdfs上开发的面向列的分布式数据库，不支持sql。</li>
<li>hbase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。</li>
<li>hbase是列存储。</li>
</ol>
<p><strong>Hive只供维护用，真正查起来非常非常慢的</strong>！<br>这是因为它的底层是要通过mapreduce分布式计算的，hbase、hive、pig底层都是这样的。但整体来说hadoop还是比较快的，因为它是进行海量数据存储和分布式计算，这个速度已经很不错了。<br>Hive和Hbase有各自不同的特征：<strong>hive是高延迟、结构化和面向分析的，hbase是低延迟、非结构化和面向编程的。Hive数据仓库在hadoop上是高延迟的。</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Hive 是为了简化编写MapReduce程序而生的&lt;/strong&gt;，使用MapReduce做过数据分析的人都知道，很多分析程序除业务逻辑不同外，程序流程基本一样。在这种 情况下，就需要Hive这样的用戶编程接口。Hive本身不存储和计算数据，它完全依赖于
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hbase" scheme="http://yoursite.com/tags/hbase/"/>
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="hdfs" scheme="http://yoursite.com/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ下的生产消费者模式与订阅发布模式</title>
    <link href="http://yoursite.com/2016/12/27/RabbitMQ%E4%B8%8B%E7%9A%84%E7%94%9F%E4%BA%A7%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F%E4%B8%8E%E8%AE%A2%E9%98%85%E5%8F%91%E5%B8%83%E6%A8%A1%E5%BC%8F/"/>
    <id>http://yoursite.com/2016/12/27/RabbitMQ下的生产消费者模式与订阅发布模式/</id>
    <published>2016-12-27T02:08:09.000Z</published>
    <updated>2017-02-17T07:50:54.948Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>生产消费者模式与订阅发布模式是使用消息中间件时常用的两种模式，用于功能解耦和分布式系统间的消息通信。</p>
<h2 id="数据接入"><a href="#数据接入" class="headerlink" title="数据接入"></a>数据接入</h2><p>一个用户行为采集系统，负责从App端采集用户点击行为数据。通常会将数据上报和数据处理分离开，即App端通过REST API上报数据，后端拿到数据后放入队列中就立刻返回，而数据处理则另外使用Worker从队列中取出数据来做，如下图所示：<br><img src="http://p1.bqimg.com/567571/cc3a7aa1c382177e.jpg" alt=""><br>这样做的好处有：第一，功能分离，上报的API接口不关心数据处理功能，只负责接入数据；第二，数据缓冲，数据上报的速率是不可控的，取决于用户使用频率，采用该模式可以一定程度地缓冲数据；第三，易于扩展，在数据量大时，通过增加数据处理Worker来扩展，提高处理速率。这便是典型的<strong>生产消费者模式</strong>，数据上报为生产者，数据处理为消费者。</p>
<h2 id="事件分发"><a href="#事件分发" class="headerlink" title="事件分发"></a>事件分发</h2><p>一个电商系统，那么，用户“收藏”、“下单”、“付款”等行为都是非常重要的事件，通常后端服务在完成相应的功能处理外，还需要在这些事件点上做很多其他处理动作，比如发送短信通知、记录用户积分等等。我们可以将这些额外的处理动作放到每个模块中，但这并不是优雅的实现，不利于功能解耦和代码维护。<br>??我们需要的是一个事件分发系统，在各个功能模块中将对应的事件发布出来，由对其感兴趣的处理者进行处理。这里涉及两个角色：A对B感兴趣，A是处理者，B是事件，由事件处理器完成二者的绑定，并向消息中心订阅事件。服务模块是后端的业务逻辑服务，在不同的事件点发布事件，事件经过消息中心分发给事件处理器对应的处理者。整个流程如下图所示。这边是典型的<strong>订阅发布模式</strong>。<br><img src="http://p1.bqimg.com/567571/9923cb1907dbecb8.jpg" alt=""></p>
<h1 id="RabbitMQ核心概念"><a href="#RabbitMQ核心概念" class="headerlink" title="RabbitMQ核心概念"></a>RabbitMQ核心概念</h1><h2 id="通信方式"><a href="#通信方式" class="headerlink" title="通信方式"></a>通信方式</h2><p>RabbitMQ是基于AMQP协议来实现的消息中间件。AMQP，类似于HTTP协议，也是一个应用层的协议，网络层使用TCP来通信。因此，RabbitMQ也是典型的C-S模型，准确地说是C-S-C模型，因为伴随着RabbitMQ的使用，总是会有Producer与Consumer两个Client和一个Broker Server。<br><img src="http://p1.bqimg.com/567571/4e6b03c753eec38a.jpg" alt=""><br>Client要与Server进行通信，就必须先建立连接，RabbitMQ中有Connection与Channel两个概念，前者就是一个TCP连接，后者是在这个连接上的虚拟概念，负责逻辑上的数据传递，因此，为了节省资源，一般在一个客户端中建立一个Connection，每次使用时再分配一个Channel即可。</p>
<h2 id="消息体"><a href="#消息体" class="headerlink" title="消息体"></a>消息体</h2><p>Message是RabbitMQ中的消息体概念。类似HTTP传输中，有header和body两部分数据，Message中也有Attributes和Payload两部分数据，前者是一些元信息，后者是传递的消息数据实体。</p>
<h2 id="消息投递"><a href="#消息投递" class="headerlink" title="消息投递"></a>消息投递</h2><p>Exchange、Queue与Routing Key三个概念是理解RabbitMQ消息投递的关键。RabbitMQ中一个核心的原则是，消息不能直接投递到Queue中。Producer只能将自己的消息投递到Exchange中，由Exchange按照routing_key投递到对应的Queue中，具体的架构参见下图。细细品味就会体会到这样设计的精妙之处。<br><img src="http://i1.piimg.com/567571/50d6da93fec7a4e5.jpg" alt=""></p>
<ol>
<li>在Consumer Worker中，声明自己对哪个Exchange感兴趣，并将自己的Queue绑定到自己感兴趣的一组routing_key上，建立相应的映射关系；</li>
<li>在Producer中，将消息投递一个Exchange中，并指明它的routing_key。由此可见，Queue这个概念只是对Consumer可见，Producer并不关心消息被投递到哪个Queue中。 </li>
<li>看过RabbitMQ的”Hello World”教程的童鞋可能会发现在那里面的图中并没有看到Exchange和routing_key的踪迹，但这并不意味着RabbitMQ可以支持直接将消息投递到Queue中，而是在内部使用了默认的Exchange和routing_key了。默认情况下，RabbitMQ使用名称为“amq.direct”的Direct Exchange，routing_key默认名字与Queue保持一致。<br>搞清楚上述概念，就不难理解Exchange的四种类型了。Direct、Fanout、Topic、Headers，区别在于如何将消息从Exchange投递到Queue中。Direct使用具体的routing_key来投递；Fanout则忽略routing_key，直接广播给所有的Queue；Topic是使用模糊匹配来对一组routing_key进行投递；Headers也是忽略routing_key，使用消息中的Headers信息来投递。<h2 id="消息可靠性"><a href="#消息可靠性" class="headerlink" title="消息可靠性"></a>消息可靠性</h2></li>
<li>消息确认机制。Consumer处理完消息后，需要发送确认消息给Broker Server，可以选择“确认接收”、“丢弃”、“重新投递”三种方式。如果Consumer在Broker Server收到确认消息之前挂了，Broker Server便会重新投递该消息。</li>
<li>可以选择数据持久化，这样即使RabbitMQ重启，也不会丢失消息。<h1 id="生产消费者模式"><a href="#生产消费者模式" class="headerlink" title="生产消费者模式"></a>生产消费者模式</h1><img src="http://p1.bqimg.com/567571/13204f61927c1570.jpg" alt=""><br>“数据接入”的场景，架构如上图所示，对于上报的数据，如果是special的行为，需要优先处理。从上图可以看到，数据上报端负责将数据投递到RabbitMQ对应的Exchange，并指明routing_key是common还是special。数据处理端，可以根据情况启多个Woker来消费数据，但至少需要两个，一个用来处理common数据，一个用来处理special的数据。<h1 id="订阅发布模式"><a href="#订阅发布模式" class="headerlink" title="订阅发布模式"></a>订阅发布模式</h1><img src="http://p1.bqimg.com/567571/c820244527b48013.jpg" alt=""><br>“事件分发”的场景，架构如上图所示，使用event name/id来作为RabbitMQ的routing key的名字。Event Processor 01对event 01 和event 02感兴趣，则在启动Consumer Worker时，将自己的Queue绑定到这两个routing key上即可，其他Event Processor也是如此，这样便完成了事件的订阅。当有事件发布时，消息便会按照event name/id被投递到对应的Queue中。 <h1 id="消息持久化"><a href="#消息持久化" class="headerlink" title="消息持久化"></a>消息持久化</h1><img src="http://www.itdadao.com/articles/c15a901095p0.html" alt=""><br><img src="http://www.cnblogs.com/xiazh/archive/2011/04/29/2004859.html" alt=""><br><img src="http://blog.csdn.net/lk10207160511/article/details/50334173" alt=""></li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;生产消费者模式与订阅发布模式是使用消息中间件时常用的两种模式，用于功能解耦和分布式系统间的消息通信。&lt;/p&gt;
&lt;h2 id=&quot;数据接入&quot;&gt;&lt;
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="RabbitMQ" scheme="http://yoursite.com/tags/RabbitMQ/"/>
    
      <category term="MQ" scheme="http://yoursite.com/tags/MQ/"/>
    
  </entry>
  
  <entry>
    <title>离线安装 Cloudera ( CDH 5.x )</title>
    <link href="http://yoursite.com/2016/12/20/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%20Cloudera%20(%20CDH%205.x%20)/"/>
    <id>http://yoursite.com/2016/12/20/离线安装 Cloudera ( CDH 5.x )/</id>
    <published>2016-12-20T02:37:06.000Z</published>
    <updated>2017-02-17T02:10:12.332Z</updated>
    
    <content type="html"><![CDATA[<h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><ul>
<li>系统 centos 6.5</li>
<li>jdk 1.8</li>
<li>三台主机节点<br>  节点角色说明</li>
</ul>
<table>
<thead>
<tr>
<th>ip</th>
<th style="text-align:center">主机名</th>
<th style="text-align:right">角色描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>10.206.2.181</td>
<td style="text-align:center">hadoop-master</td>
<td style="text-align:right">cm，agent</td>
</tr>
<tr>
<td>10.206.2.182</td>
<td style="text-align:center">hadoop-slave1</td>
<td style="text-align:right">agent</td>
</tr>
<tr>
<td>10.206.2.183</td>
<td style="text-align:center">hadoop-slave2</td>
<td style="text-align:right">agent</td>
</tr>
</tbody>
</table>
<ul>
<li>域名解析<br>配置/etc/hosts, 将以下代码追加到文件末尾即可<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">sudo vim /etc/hosts</div></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">10.206.2.181 hadoop-master </div><div class="line">10.206.2.182 hadoop-slave1</div><div class="line">10.206.2.183 hadoop-slave2</div></pre></td></tr></table></figure>
<ul>
<li>关闭iptable 或配置 iptable策略</li>
<li>关闭SELinux</li>
<li>配置免密码ssh登录</li>
<li>安装jdk（在所有节点操作）</li>
<li>时间同步</li>
<li>准备包（用parcel 方式安装）</li>
<li></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;准备&quot;&gt;&lt;a href=&quot;#准备&quot; class=&quot;headerlink&quot; title=&quot;准备&quot;&gt;&lt;/a&gt;准备&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;系统 centos 6.5&lt;/li&gt;
&lt;li&gt;jdk 1.8&lt;/li&gt;
&lt;li&gt;三台主机节点&lt;br&gt;  节点角色说明&lt;/li&gt;

    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="cdh" scheme="http://yoursite.com/tags/cdh/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop &amp; Hbase 自动化部署</title>
    <link href="http://yoursite.com/2016/12/08/hadoop&amp;hbase%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2016/12/08/hadoop&amp;hbase自动化部署/</id>
    <published>2016-12-08T07:50:50.000Z</published>
    <updated>2017-02-17T02:10:12.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hadoop-amp-Hbase-自动化部署"><a href="#Hadoop-amp-Hbase-自动化部署" class="headerlink" title="Hadoop &amp; Hbase 自动化部署"></a>Hadoop &amp; Hbase 自动化部署</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>项目组只有一台高配的服务器，故决定使用docker搭建Hadoop&amp;Hbase等集群环境。</p>
<h3 id="docker"><a href="#docker" class="headerlink" title="docker"></a>docker</h3><p>Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。</p>
<h3 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h3><ul>
<li>hadoop-hbase-hive-cluster-docker-master<ul>
<li>config</li>
<li>Dockerfile</li>
<li>program</li>
<li>resize-cluster.sh</li>
<li>start-container.sh</li>
</ul>
</li>
</ul>
<ol>
<li>config 目录存放配值文件</li>
<li>Dockerfile docker命令脚本，用于构建Dokcer镜像</li>
<li>program hadoop、hbase等安装包目录</li>
<li>resize-cluster.sh 重建镜像脚本</li>
<li>start-container.sh 启动容器脚本</li>
</ol>
<h3 id="Dockerfile-说明"><a href="#Dockerfile-说明" class="headerlink" title="Dockerfile 说明"></a>Dockerfile 说明</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">FROM rastasheep/ubuntu-sshd:latest  # 基于rastasheep/ubuntu-sshd镜像</div><div class="line"></div><div class="line">MAINTAINER zfylin   # author</div><div class="line"></div><div class="line">WORKDIR /root #工作目录</div><div class="line"></div><div class="line"># 配置JDK</div><div class="line">ADD program/jdk-8u101-linux-x64.tar.gz /usr/local</div><div class="line">RUN mv /usr/local/jdk1.8.0_101 /usr/local/jdk</div><div class="line"></div><div class="line"># install hadoop 2.7.2</div><div class="line">ADD program/hadoop-2.7.2.tar.gz /usr/local</div><div class="line">RUN mv /usr/local/hadoop-2.7.2 /usr/local/hadoop</div><div class="line"></div><div class="line"># install hbase 1.2.3 </div><div class="line">ADD program/hbase-1.2.3-bin.tar.gz /usr/local</div><div class="line">RUN mv /usr/local/hbase-1.2.3 /usr/local/hbase</div><div class="line"></div><div class="line"># install hive-2.1.0</div><div class="line">ADD program/apache-hive-2.1.0-bin.tar.gz /usr/local</div><div class="line">RUN mv /usr/local/apache-hive-2.1.0-bin /usr/local/hive</div><div class="line">ADD program/mysql-connector-java-5.1.40.tar.gz /tmp</div><div class="line">RUN cp /tmp/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/hive/lib</div><div class="line"></div><div class="line"># install sqoop-1.4.6</div><div class="line">ADD program/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz /usr/local</div><div class="line">RUN mv /usr/local/sqoop-1.4.6.bin__hadoop-2.0.4-alpha /usr/local/sqoop</div><div class="line">RUN cp /tmp/mysql-connector-java-5.1.40/mysql-connector-java-5.1.40-bin.jar /usr/local/sqoop/lib</div><div class="line"></div><div class="line"># set environment variable</div><div class="line">ENV JAVA_HOME=/usr/local/jdk</div><div class="line">ENV HADOOP_HOME=/usr/local/hadoop</div><div class="line">ENV HBASE_HOME=/usr/local/hbase</div><div class="line">ENV HIVE_HOME=/usr/local/hive</div><div class="line">ENV SQOOP_HOME=/usr/local/sqoop</div><div class="line">ENV PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/hbase/bin:/usr/local/hive/bin:/usr/local/sqoop/bin:/usr/local/jdk/bin</div><div class="line"></div><div class="line"># ssh without key</div><div class="line">RUN ssh-keygen -t rsa -f ~/.ssh/id_rsa -P &apos;&apos; &amp;&amp; \</div><div class="line">    cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</div><div class="line"></div><div class="line"># mkdir hadoop log</div><div class="line">RUN  mkdir $HADOOP_HOME/logs</div><div class="line"></div><div class="line"># copy configs</div><div class="line">COPY config/* /tmp/</div><div class="line">RUN mv /tmp/ssh_config ~/.ssh/config &amp;&amp; \</div><div class="line">    mv /tmp/hadoop-env.sh /usr/local/hadoop/etc/hadoop/hadoop-env.sh &amp;&amp; \</div><div class="line">    mv /tmp/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/slaves $HADOOP_HOME/etc/hadoop/slaves &amp;&amp; \</div><div class="line">    mv /tmp/start-hadoop.sh ~/start-hadoop.sh &amp;&amp; \</div><div class="line">    mv /tmp/run-wordcount.sh ~/run-wordcount.sh &amp;&amp; \</div><div class="line">    mv /tmp/hbase-env.sh $HBASE_HOME/conf/hbase-env.sh &amp;&amp; \</div><div class="line">    mv /tmp/hbase-site.xml $HBASE_HOME/conf/hbase-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/regionservers $HBASE_HOME/conf/regionservers &amp;&amp; \</div><div class="line">    mv /tmp/start-hbase.sh ~/start-hbase.sh &amp;&amp; \</div><div class="line">    mv /tmp/stop-hbase.sh ~/stop-hbase.sh &amp;&amp; \</div><div class="line">    mv /tmp/hive-site.xml $HIVE_HOME/conf/hive-site.xml &amp;&amp; \</div><div class="line">    mv /tmp/hive-log4j2.properties $HIVE_HOME/conf/hive-log4j2.properties &amp;&amp; \</div><div class="line">    mv /tmp/hive-exec-log4j2.properties $HIVE_HOME/conf/hive-exec-log4j2.properties &amp;&amp; \</div><div class="line">   mv /tmp/hive-config.sh ~/hive-config.sh &amp;&amp; \</div><div class="line">   mv /tmp/sqoop-env.sh $&#123;SQOOP_HOME&#125;/conf</div><div class="line"></div><div class="line">RUN chmod +x ~/start-hadoop.sh &amp;&amp; \</div><div class="line">    chmod +x ~/run-wordcount.sh &amp;&amp; \</div><div class="line">    chmod +x $HADOOP_HOME/sbin/start-dfs.sh &amp;&amp; \</div><div class="line">    chmod +x $HADOOP_HOME/sbin/start-yarn.sh &amp;&amp; \</div><div class="line">    chmod +x ~/start-hbase.sh &amp;&amp; \</div><div class="line">    chmod +x $HBASE_HOME/bin/start-hbase.sh &amp;&amp; \</div><div class="line">    chmod +x ~/stop-hbase.sh &amp;&amp; \</div><div class="line">    chmod +x $&#123;HBASE_HOME&#125;/bin/stop-hbase.sh &amp;&amp; \</div><div class="line">    chmod +x ~/hive-config.sh</div><div class="line"></div><div class="line">CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service ssh start; bash&quot;]</div><div class="line"></div><div class="line">EXPOSE 22 7373 7946 9000 50010 50020 50070 50075 50090 50475 8030 8031 8032 8033 8040 8042 8060 8088 50060 2818 60000 60010</div></pre></td></tr></table></figure>
<h3 id="resize-cluster-sh"><a href="#resize-cluster-sh" class="headerlink" title="resize-cluster.sh"></a>resize-cluster.sh</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line"># N is the node number of hadoop cluster</div><div class="line">N=$&#123;1:-3&#125;   # 默认3个节点</div><div class="line"></div><div class="line">if [ $# = 0 ]</div><div class="line">then</div><div class="line">        echo &quot;Please specify the node number of hadoop cluster!&quot;</div><div class="line">        exit 1</div><div class="line">fi</div><div class="line"></div><div class="line"># change slaves file</div><div class="line">i=1</div><div class="line">rm config/slaves</div><div class="line">rm config/regionservers</div><div class="line">while [ $i -lt $N ]</div><div class="line">do</div><div class="line">        echo &quot;hadoop-slave$i&quot; &gt;&gt; config/slaves</div><div class="line">        # 同步修改hbase-site.xml hbase.zookeeper.quorum配置项</div><div class="line">        # 如果 N = 3, 则 value 为 “hadoop-master,hadoop-slave1,hadoop-slave2”</div><div class="line">        # 如果 N = 5, 则 value 为  &quot;hadoop-master,hadoop-slave1,hadoop-slave2,hadoop-slave3, hadoop-slave4&quot;</div><div class="line">        echo &quot;hadoop-slave$i&quot; &gt;&gt; config/regionservers </div><div class="line">        ((i++))</div><div class="line">done</div><div class="line"></div><div class="line">echo &quot;&quot;</div><div class="line"></div><div class="line">echo -e &quot;\nbuild docker hadoop image\n&quot;</div><div class="line"></div><div class="line"># rebuild zfylin/hadoop image</div><div class="line">sudo docker build -t zfylin/hadoop-hbase:1.0 .</div><div class="line"></div><div class="line">echo &quot;&quot;</div></pre></td></tr></table></figure>
<h3 id="start-container-sh"><a href="#start-container-sh" class="headerlink" title="start-container.sh"></a>start-container.sh</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">#!/bin/bash</div><div class="line"></div><div class="line"># the default node number is 3</div><div class="line">N=$&#123;1:-3&#125;</div><div class="line">HADOOP_IAMGES_NAME=zfylin/hadoop-hbase:1.0</div><div class="line">NET_NAME=none</div><div class="line">VOLUMN_PATH=/home/zfy/data/hadoop-cluster</div><div class="line"></div><div class="line">declare -a users</div><div class="line"># node ip, users[1] 为 master ip，其他为 slave ip</div><div class="line"># 有多少个node，就需要配置多少ip</div><div class="line">users=([1]=&apos;10.206.19.121&apos; [2]=&apos;10.206.19.122&apos; [3]=&apos;10.206.19.123&apos;)</div><div class="line"># host 配置，有多少个node，就需要配置多少host</div><div class="line">h0=&apos;mirror.centos.org:10.204.76.222&apos;</div><div class="line">h1=&apos;hadoop-master:10.206.19.121&apos;</div><div class="line">h2=&apos;hadoop-slave1:10.206.19.122&apos;</div><div class="line">h3=&apos;hadoop-slave2:10.206.19.123&apos;</div><div class="line">prefix=24</div><div class="line">via=&apos;10.206.16.11&apos;</div><div class="line"></div><div class="line"># start hadoop master container</div><div class="line">sudo docker rm -f hadoop-master &amp;&gt; /dev/null</div><div class="line">echo &quot;start hadoop-master container...&quot;</div><div class="line">sudo docker run -itd \</div><div class="line">                --net=$&#123;NET_NAME&#125; \</div><div class="line">                --privileged=true \</div><div class="line">                --name hadoop-master \</div><div class="line">                --hostname hadoop-master \</div><div class="line">                --add-host=&quot;$h0&quot; \</div><div class="line">                --add-host=&quot;$h1&quot; \</div><div class="line">                --add-host=&quot;$h2&quot; \</div><div class="line">                --add-host=&quot;$h3&quot; \</div><div class="line">                -v $&#123;VOLUMN_PATH&#125;/hadoop-master/hdfs:/root/hdfs \</div><div class="line">                $&#123;HADOOP_IAMGES_NAME&#125; &amp;&gt; /dev/null</div><div class="line"></div><div class="line">echo &quot;pipework br33 hadoop-master $&#123;users[1]&#125;/$prefix@$via&quot;</div><div class="line"># pipework 绑定hadoop-master ip</div><div class="line">pipework br33 hadoop-master $&#123;users[1]&#125;/$prefix@$via</div><div class="line"></div><div class="line"># start hadoop slave container</div><div class="line">i=1</div><div class="line">while [ $i -lt $N ]</div><div class="line">do</div><div class="line">        sudo docker rm -f hadoop-slave$i &amp;&gt; /dev/null</div><div class="line">        echo &quot;start hadoop-slave$i container...&quot;</div><div class="line">        sudo docker run -itd \</div><div class="line">                        --net=$&#123;NET_NAME&#125; \</div><div class="line">                        --privileged=true \</div><div class="line">                        --add-host=&quot;$h0&quot; \</div><div class="line">                        --add-host=&quot;$h1&quot; \</div><div class="line">                        --add-host=&quot;$h2&quot; \</div><div class="line">                        --add-host=&quot;$h3&quot; \</div><div class="line">                        --name hadoop-slave$i \</div><div class="line">                        --hostname hadoop-slave$i \</div><div class="line">                        -v $&#123;VOLUMN_PATH&#125;/hadoop-slave$i/hdfs:/root/hdfs \</div><div class="line">                        $&#123;HADOOP_IAMGES_NAME&#125; &amp;&gt; /dev/null</div><div class="line">        host_name=hadoop-slave$i</div><div class="line">        i=$(( $i + 1 ))</div><div class="line">        echo &quot;pipework br33 $host_name $&#123;users[$i]&#125;/$prefix@$via&quot;</div><div class="line">        # pipework 绑定hadoop-slave$i ip</div><div class="line">        pipework br33 $host_name $&#123;users[$i]&#125;/$prefix@$via</div><div class="line"></div><div class="line">done</div><div class="line"></div><div class="line"># get into hadoop master container</div><div class="line">sudo docker exec -it hadoop-master bash</div></pre></td></tr></table></figure>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><ul>
<li>构建Docker镜像<br>  sudo ./resize-cluster.sh </li>
<li>启动镜像<br> sudo  ./start-container.sh </li>
<li>启动hadoop<br>  ./start-hadoop.sh</li>
<li>启动hbase<br> ./start-hbase.sh</li>
<li>启动hive<br>hiveserver2 start</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Hadoop-amp-Hbase-自动化部署&quot;&gt;&lt;a href=&quot;#Hadoop-amp-Hbase-自动化部署&quot; class=&quot;headerlink&quot; title=&quot;Hadoop &amp;amp; Hbase 自动化部署&quot;&gt;&lt;/a&gt;Hadoop &amp;amp; Hbase
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hbase" scheme="http://yoursite.com/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Centos代理设置</title>
    <link href="http://yoursite.com/2016/11/28/Centos%20%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"/>
    <id>http://yoursite.com/2016/11/28/Centos 代理设置/</id>
    <published>2016-11-28T00:50:02.000Z</published>
    <updated>2017-02-17T02:10:12.113Z</updated>
    
    <content type="html"><![CDATA[<h2 id="系统级代理"><a href="#系统级代理" class="headerlink" title="系统级代理"></a>系统级代理</h2><p>vi /etc/profile<br>添加下面内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">http_proxy = http://username:password@yourproxy:8080/</div><div class="line">ftp_proxy = http://username:password@yourproxy:8080/</div><div class="line">export http_proxy</div><div class="line">export ftp_proxy</div></pre></td></tr></table></figure></p>
<h2 id="yum-代理"><a href="#yum-代理" class="headerlink" title="yum 代理"></a>yum 代理</h2><p>vi /etc/yum.conf<br>添加下面内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">proxy = http://username:password@yourproxy:8080/</div></pre></td></tr></table></figure></p>
<h2 id="wget代理"><a href="#wget代理" class="headerlink" title="wget代理"></a>wget代理</h2><p>vi /etc/wgetrc<br>添加下面内容<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">http_proxy=http://username:password@proxy_ip:port/</div><div class="line">ftp_proxy=http://username:password@proxy_ip:port/</div></pre></td></tr></table></figure></p>
<h2 id="docker代理"><a href="#docker代理" class="headerlink" title="docker代理"></a>docker代理</h2><ol>
<li><p>创建目录</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">mkdir /etc/systemd/system/docker.service.d</div></pre></td></tr></table></figure>
</li>
<li><p>创建文件</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">touch /etc/systemd/system/docker.service.d/http-proxy.conf</div></pre></td></tr></table></figure>
</li>
<li><p>配置http-proxy.conf文件</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[Service]</div><div class="line">Environment=&quot;HTTP_PROXY=http://proxy.ip.com:80&quot;</div></pre></td></tr></table></figure>
</li>
<li><p>daemon重新reload 并重启docker</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">systemctl daemon-reload</div><div class="line">systemctl restart docker</div></pre></td></tr></table></figure>
</li>
<li><p>检查变量是否加载</p>
 <figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">systemctl show docker --property Environment</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;系统级代理&quot;&gt;&lt;a href=&quot;#系统级代理&quot; class=&quot;headerlink&quot; title=&quot;系统级代理&quot;&gt;&lt;/a&gt;系统级代理&lt;/h2&gt;&lt;p&gt;vi /etc/profile&lt;br&gt;添加下面内容&lt;br&gt;&lt;figure class=&quot;highlight plai
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="centos" scheme="http://yoursite.com/tags/centos/"/>
    
      <category term="代理" scheme="http://yoursite.com/tags/%E4%BB%A3%E7%90%86/"/>
    
      <category term="dokcer" scheme="http://yoursite.com/tags/dokcer/"/>
    
  </entry>
  
  <entry>
    <title>Centos7 修改 hostname</title>
    <link href="http://yoursite.com/2016/11/25/Centos7%20%E4%BF%AE%E6%94%B9hostname/"/>
    <id>http://yoursite.com/2016/11/25/Centos7 修改hostname/</id>
    <published>2016-11-25T01:49:53.000Z</published>
    <updated>2017-02-17T02:10:12.127Z</updated>
    
    <content type="html"><![CDATA[<p>在CentOS或RHEL中，有三种定义的主机名:a、静态的（static），b、瞬态的（transient），以及 c、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，“灵活”主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户（如Dan’s Computer）。</p>
<p>在CentOS/RHEL 7中，有个叫hostnamectl的命令行工具，它允许你查看或修改与主机名相关的配置。<br>要查看主机名相关的设置：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ hostnamectl status</div></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@zfy-79 zfy]# hostnamectl status</div><div class="line">   Static hostname: zfy-79</div><div class="line">         Icon name: computer-desktop</div><div class="line">           Chassis: desktop</div><div class="line">        Machine ID: 89b2147b6a1f4fe1a89148cfd53dd727</div><div class="line">           Boot ID: ee5625e25b494acc804e49043dcd8626</div><div class="line">  Operating System: CentOS Linux 7 (Core)</div><div class="line">       CPE OS Name: cpe:/o:centos:centos:7</div><div class="line">            Kernel: Linux 3.10.0-327.36.3.el7.x86_64</div><div class="line">      Architecture: x86-64</div></pre></td></tr></table></figure>
<p>同时修改所有三个主机名：静态、瞬态和灵活主机名：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[root@zfy-79 zfy]# sudo hostnamectl set-hostname dev-79</div><div class="line">[root@zfy-79 zfy]# hostnamectl status</div><div class="line">   Static hostname: dev-79</div><div class="line">         Icon name: computer-desktop</div><div class="line">           Chassis: desktop</div><div class="line">        Machine ID: 89b2147b6a1f4fe1a89148cfd53dd727</div><div class="line">           Boot ID: ee5625e25b494acc804e49043dcd8626</div><div class="line">  Operating System: CentOS Linux 7 (Core)</div><div class="line">       CPE OS Name: cpe:/o:centos:centos:7</div><div class="line">            Kernel: Linux 3.10.0-327.36.3.el7.x86_64</div><div class="line">      Architecture: x86-64</div></pre></td></tr></table></figure>
<p>如果你只想修改特定的主机名（静态，瞬态或灵活），你可以使用“–static”，“–transient”或“–pretty”选项。<br><strong>注意，你不必重启机器以激活永久主机名修改。上面的命令会立即修改内核主机名。注销并重新登入后在命令行提示来观察新的静态主机名。</strong></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在CentOS或RHEL中，有三种定义的主机名:a、静态的（static），b、瞬态的（transient），以及 c、灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="centos" scheme="http://yoursite.com/tags/centos/"/>
    
      <category term="hostname" scheme="http://yoursite.com/tags/hostname/"/>
    
  </entry>
  
  <entry>
    <title>Dockerfile命令介绍及实例</title>
    <link href="http://yoursite.com/2016/11/24/Dockerfile%E5%91%BD%E4%BB%A4%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%AE%9E%E4%BE%8B/"/>
    <id>http://yoursite.com/2016/11/24/Dockerfile命令介绍及实例/</id>
    <published>2016-11-24T12:04:02.000Z</published>
    <updated>2017-02-17T02:10:12.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker简介"><a href="#Docker简介" class="headerlink" title="Docker简介"></a>Docker简介</h2><p>Docker项目提供了构建在Linux内核功能之上，协同在一起的的高级工具。其目标是帮助开发和运维人员更容易地跨系统跨主机交付应用程序和他们的依赖。Docker通过Docker容器，一个安全的，基于轻量级容器的环境，来实现这个目标。这些容器由镜像创建，而镜像可以通过命令行手工创建或 者通过Dockerfile自动创建。</p>
<h2 id="Dokcerfile"><a href="#Dokcerfile" class="headerlink" title="Dokcerfile"></a>Dokcerfile</h2><p>Dockerfile是由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。它们简化了从头到尾的流程并极大的简化了部署工作。Dockerfile从FROM命令开始，紧接着跟随者各种方法，命令和参数。其产出为一个新的可以用于创建容器的镜像。</p>
<h2 id="Dockerfile-语法"><a href="#Dockerfile-语法" class="headerlink" title="Dockerfile 语法"></a>Dockerfile 语法</h2><h3 id="Dockerfile-语法示例"><a href="#Dockerfile-语法示例" class="headerlink" title="Dockerfile 语法示例"></a>Dockerfile 语法示例</h3><p>Dockerfile语法由两部分构成，注释和命令+参数<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Line blocks used for commenting</div><div class="line">command argument argument ..</div></pre></td></tr></table></figure></p>
<p>一个简单的例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Print &quot;Hello docker!&quot;</div><div class="line">RUN echo &quot;Hello docker!&quot;</div></pre></td></tr></table></figure></p>
<h3 id="Dockerfile-命令"><a href="#Dockerfile-命令" class="headerlink" title="Dockerfile 命令"></a>Dockerfile 命令</h3><p>Dockerfile有十几条命令可用于构建镜像，下文将简略介绍这些命令。</p>
<h4 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h4><p>ADD命令有两个参数，源和目标。它的基本作用是从源系统的文件系统上复制文件到目标容器的文件系统。如果源是一个URL，那该URL的内容将被下载并复制到容器中。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: ADD [source directory or URL] [destination directory]</div><div class="line">ADD /my_app_folder /my_app_folder</div></pre></td></tr></table></figure></p>
<h4 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h4><p>和RUN命令相似，CMD可以用于执行特定的命令。和RUN不同的是，这些命令不是在镜像构建的过程中执行的，而是在用镜像构建容器后被调用。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage 1: CMD application &quot;argument&quot;, &quot;argument&quot;, ..</div><div class="line">CMD &quot;echo&quot; &quot;Hello docker!&quot;</div></pre></td></tr></table></figure></p>
<h4 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h4><p>ENTRYPOINT 帮助你配置一个容器使之可执行化，如果你结合CMD命令和ENTRYPOINT命令，你可以从CMD命令中移除“application”而仅仅保留参数，参数将传递给ENTRYPOINT命令。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: ENTRYPOINT application &quot;argument&quot;, &quot;argument&quot;, ..</div><div class="line"># Remember: arguments are optional. They can be provided by CMD</div><div class="line"># or during the creation of a container.</div><div class="line">ENTRYPOINT echo</div><div class="line"># Usage example with CMD:</div><div class="line"># Arguments set with CMD can be overridden during *run*</div><div class="line">CMD &quot;Hello docker!&quot;</div><div class="line">ENTRYPOINT echo</div></pre></td></tr></table></figure></p>
<h4 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h4><p>ENV命令用于设置环境变量。这些变量以”key=value”的形式存在，并可以在容器内被脚本或者程序调用。这个机制给在容器中运行应用带来了极大的便利。<br><em>ps：ENV配置镜像的环境变量，但是这样设置的环境变量只能在运行时使用/bin/bash时才会生效。当用ssh登录到容器后，这些变量将失效</em><br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: ENV key value</div><div class="line">ENV SERVER_WORKS 4</div></pre></td></tr></table></figure></p>
<h4 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h4><p>EXPOSE用来指定端口，使容器内的应用可以通过端口和外界交互。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: EXPOSE [port]</div><div class="line">EXPOSE 8080</div></pre></td></tr></table></figure></p>
<h4 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h4><p>FROM命令可能是最重要的Dockerfile命令。改命令定义了使用哪个基础镜像启动构建流程。基础镜像可以为任意镜像。如果基础镜像没有被发现，Docker将试图从Docker image index来查找该镜像。FROM命令必须是Dockerfile的首个命令。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: FROM [image name]</div><div class="line">FROM ubuntu</div></pre></td></tr></table></figure></p>
<h4 id="MAINTAINER"><a href="#MAINTAINER" class="headerlink" title="MAINTAINER"></a>MAINTAINER</h4><p>我建议这个命令放在Dockerfile的起始部分，虽然理论上它可以放置于Dockerfile的任意位置。这个命令用于声明作者，并应该放在FROM的后面。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: MAINTAINER [name]</div><div class="line">MAINTAINER authors_name</div></pre></td></tr></table></figure></p>
<h4 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h4><p>RUN命令是Dockerfile执行命令的核心部分。它接受命令作为参数并用于创建镜像。不像CMD命令，RUN命令用于创建镜像（在之前commit的层之上形成新的层）。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: RUN [command]</div><div class="line">RUN aptitude install -y riak</div></pre></td></tr></table></figure></p>
<h4 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h4><p>USER命令用于设置运行容器的UID。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: USER [UID]</div><div class="line">USER 751</div></pre></td></tr></table></figure></p>
<h4 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h4><p>VOLUME命令用于让你的容器访问宿主机上的目录。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: VOLUME [&quot;/dir_1&quot;, &quot;/dir_2&quot; ..]</div><div class="line">VOLUME [&quot;/my_files&quot;]</div></pre></td></tr></table></figure></p>
<h4 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h4><p>WORKDIR命令用于设置CMD指明的命令的运行目录。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Usage: WORKDIR /path</div><div class="line">WORKDIR ~/</div></pre></td></tr></table></figure></p>
<h3 id="如何使用Dockerfiles"><a href="#如何使用Dockerfiles" class="headerlink" title="如何使用Dockerfiles"></a>如何使用Dockerfiles</h3><p>使用Dockerfiles和手工使用Docker Daemon运行命令一样简单。脚本运行后输出为新的镜像ID。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Build an image using the Dockerfile at current location</div><div class="line"># Example: sudo docker build -t [name] .</div><div class="line">sudo docker build -t my_mongodb .</div></pre></td></tr></table></figure></p>
<h2 id="Dockerfile-示例：创建一个Nginx的镜像"><a href="#Dockerfile-示例：创建一个Nginx的镜像" class="headerlink" title="Dockerfile 示例：创建一个Nginx的镜像"></a>Dockerfile 示例：创建一个Nginx的镜像</h2><h3 id="基础镜像"><a href="#基础镜像" class="headerlink" title="基础镜像"></a>基础镜像</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">############################################################</div><div class="line"># Dockerfile to build Nginx Installed Containers</div><div class="line"># Based on Ubuntu</div><div class="line">############################################################</div><div class="line"># Set the base image to Ubuntu</div><div class="line">FROM ubuntu</div><div class="line"># File Author / Maintainer</div><div class="line">MAINTAINER Maintaner Name</div></pre></td></tr></table></figure>
<h3 id="安装Nginx"><a href="#安装Nginx" class="headerlink" title="安装Nginx"></a>安装Nginx</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Install Nginx</div><div class="line"># Add application repository URL to the default sources</div><div class="line">RUN echo &quot;deb http://archive.ubuntu.com/ubuntu/ raring main universe&quot; &gt;&gt; /etc/apt/sources.list</div><div class="line"># Update the repository</div><div class="line">RUN apt-get update</div><div class="line"># Install necessary tools</div><div class="line">RUN apt-get install -y nano wget dialog net-tools</div><div class="line"># Download and Install Nginx</div><div class="line">RUN apt-get install -y nginx</div></pre></td></tr></table></figure>
<h3 id="Bootstrapping"><a href="#Bootstrapping" class="headerlink" title="Bootstrapping"></a>Bootstrapping</h3><p>安装Nginx后，我们需要配置Nginx并且替换掉默认的配置文件<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># Remove the default Nginx configuration file</div><div class="line">RUN rm -v /etc/nginx/nginx.conf</div><div class="line"># Copy a configuration file from the current directory</div><div class="line">ADD nginx.conf /etc/nginx/</div><div class="line"># Append &quot;daemon off;&quot; to the beginning of the configuration</div><div class="line">RUN echo &quot;daemon off;&quot; &gt;&gt; /etc/nginx/nginx.conf</div><div class="line"># Expose ports</div><div class="line">EXPOSE 80</div><div class="line"># Set the default command to execute</div><div class="line"># when creating a new container</div><div class="line">CMD service nginx start</div></pre></td></tr></table></figure></p>
<p>保存 dockfile。</p>
<h3 id="使用Dockerfile自动构建Nginx容器"><a href="#使用Dockerfile自动构建Nginx容器" class="headerlink" title="使用Dockerfile自动构建Nginx容器"></a>使用Dockerfile自动构建Nginx容器</h3><p>因为我们命令Docker用当前目录的Nginx的配置文件替换默认的配置文件，我们要保证这个新的配置文件存在。在Dockerfile存在的目录下，创建nginx.conf：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">sudo touch nginx.conf</div></pre></td></tr></table></figure></p>
<p>然后用下述内容替换原有内容：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">worker_processes 1;</div><div class="line">events &#123; worker_connections 1024; &#125;</div><div class="line">http &#123;</div><div class="line">     sendfile on;</div><div class="line">     server &#123;</div><div class="line">         listen 80;</div><div class="line">         location / &#123;</div><div class="line">              proxy_pass http://httpstat.us/;</div><div class="line">              proxy_set_header X-Real-IP $remote_addr;</div><div class="line">         &#125;</div><div class="line">     &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>让我们保存nginx.conf。之后我们就可以用Dockerfile和配置文件来构建镜像。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Docker简介&quot;&gt;&lt;a href=&quot;#Docker简介&quot; class=&quot;headerlink&quot; title=&quot;Docker简介&quot;&gt;&lt;/a&gt;Docker简介&lt;/h2&gt;&lt;p&gt;Docker项目提供了构建在Linux内核功能之上，协同在一起的的高级工具。其目标是帮助开发
    
    </summary>
    
      <category term="docker" scheme="http://yoursite.com/categories/docker/"/>
    
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
      <category term="容器" scheme="http://yoursite.com/tags/%E5%AE%B9%E5%99%A8/"/>
    
      <category term="Dockerfile" scheme="http://yoursite.com/tags/Dockerfile/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop + Hbase 单机伪分布式安装配置</title>
    <link href="http://yoursite.com/2016/10/29/hadoop%20%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2016/10/29/hadoop 安装/</id>
    <published>2016-10-29T03:25:31.000Z</published>
    <updated>2017-02-17T02:10:12.248Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><strong>环境</strong></h2><p>centos7 + hadoop2.7.2 + jdk1.8 + hbase1.2.3</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h2><h3 id="创建hadoop用户"><a href="#创建hadoop用户" class="headerlink" title="创建hadoop用户"></a>创建hadoop用户</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line"># su hadoop</div><div class="line"># useradd -m hadoop -s /bin/bash   #创建新用户hadoop</div><div class="line"># passwd hadoop    #创建密码</div><div class="line"># vim /etc/sudoers  #赋予管理员权限</div></pre></td></tr></table></figure>
<p> 找到 root ALL=(ALL) ALL 这行<br> 然后在这行下面增加一行内容：hadoop ALL=(ALL) ALL<br><img src="http://oflrm5g9z.bkt.clouddn.com/Image%201.png" alt=""></p>
<h3 id="JAVA环境配置"><a href="#JAVA环境配置" class="headerlink" title="JAVA环境配置"></a>JAVA环境配置</h3><h3 id="安装SSH、配置SSH无密码登陆"><a href="#安装SSH、配置SSH无密码登陆" class="headerlink" title="安装SSH、配置SSH无密码登陆"></a>安装SSH、配置SSH无密码登陆</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ rpm -qa | grep ssh</div></pre></td></tr></table></figure>
<p><img src="http://oflrm5g9z.bkt.clouddn.com/Image%202.png" alt=""><br>返回结果如上图，则说明已经安装了ssh,不需要安装，否则需要通过yum进行安装。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ sudo yum install openssh-clients</div><div class="line">$ sudo yum install openssh-server</div></pre></td></tr></table></figure></p>
<p> 然后配置SSH无密码登陆<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ cd ~/.ssh/                     # 若没有该目录，请先执行一次ssh localhost</div><div class="line">$ ssh-keygen -t rsa              # 会有提示，都按回车就可以</div><div class="line">$ cat id_rsa.pub &gt;&gt; authorized_keys  # 加入授权</div><div class="line">$ chmod 600 ./authorized_keys    # 修改文件权限</div></pre></td></tr></table></figure></p>
<p>执行如下命令测试一下 SSH 是否可用：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ ssh localhost</div></pre></td></tr></table></figure></p>
<p>无需输入密码就可以直接登陆了。</p>
<h2 id="安装Haoop"><a href="#安装Haoop" class="headerlink" title="安装Haoop"></a><strong>安装Haoop</strong></h2><h3 id="下载hadoop-2-7-2-tar-gz包"><a href="#下载hadoop-2-7-2-tar-gz包" class="headerlink" title="下载hadoop-2.7.2.tar.gz包"></a>下载hadoop-2.7.2.tar.gz包</h3><h3 id="解压并修改文件权限"><a href="#解压并修改文件权限" class="headerlink" title="解压并修改文件权限"></a>解压并修改文件权限</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ sudo tar -zxf ~/下载/hadoop-2.7.2.tar.gz -C /usr/local    # 解压到/usr/local中</div><div class="line">$ cd /usr/local/</div><div class="line">$ sudo ln -s hadoop-2.7.2 hadoop            # 创建hadoop软连接</div><div class="line">$ sudo chown -R hadoop:hadoop ./hadoop        # 修改文件权限</div></pre></td></tr></table></figure>
<h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a><strong>配置环境变量</strong></h2><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ sudo vim /etc/profile</div></pre></td></tr></table></figure>
<p>添加如下内容<br><figure class="highlight vim"><table><tr><td class="code"><pre><div class="line"># hadoop Env</div><div class="line">export HADOOP_HOME=/usr/local/hadoop</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</div><div class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</div><div class="line">export YARN_HOME=$HADOOP_HOME</div><div class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</div><div class="line">export HADOOP_OPTS=<span class="string">"-Djava.library.path=$HADOOP_HOME/lib"</span></div><div class="line">export HADOOP_CLASSPATH=$&#123;JAVA_HOME&#125;/lib/tools.jar</div></pre></td></tr></table></figure></p>
<h3 id="测试hadoop是否可用"><a href="#测试hadoop是否可用" class="headerlink" title="测试hadoop是否可用"></a>测试hadoop是否可用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 root]$ hadoop version</div><div class="line">Hadoop 2.7.2</div><div class="line">Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1</div><div class="line">Compiled by jenkins on 2014-11-13T21:10Z</div><div class="line">Compiled with protoc 2.5.0</div><div class="line">From source with checksum 18e43357c8f927c0695f1e9522859d6a</div><div class="line">This command was run using /usr/local/hadoop-2.7.2/share/hadoop/common/hadoop-common-2.7.2.jar</div></pre></td></tr></table></figure>
<p>成功则会显示 如上的Hadoop 版本信息</p>
<h2 id="Hadoop伪分布式配置"><a href="#Hadoop伪分布式配置" class="headerlink" title="Hadoop伪分布式配置"></a><strong>Hadoop伪分布式配置</strong></h2><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。（/<em>Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</em>/）</p>
<ul>
<li><p>修改配置文件 core-site.xml </p>
<figure class="highlight xml"><table><tr><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件 hdfs-site.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
</li>
<li><p>修改配置hadoop-env.sh的JAVA_HOME</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="comment"># The java implementation to use.</span></div><div class="line"><span class="comment">#export JAVA_HOME=$&#123;JAVA_HOME&#125;</span></div><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk-1.8.0_45</div></pre></td></tr></table></figure>
</li>
<li><p>修改配置yarn-env.sh的JAVA_HOME</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><div class="line"><span class="comment"># some Java parameters</span></div><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk-1.8.0_45</div><div class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$JAVA_HOME</span>"</span> != <span class="string">""</span> ]; <span class="keyword">then</span></div><div class="line">  <span class="comment">#echo "run java in $JAVA_HOME"</span></div><div class="line">  JAVA_HOME=<span class="variable">$JAVA_HOME</span></div><div class="line"><span class="keyword">fi</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="NameNode-的格式化"><a href="#NameNode-的格式化" class="headerlink" title="NameNode 的格式化"></a>NameNode 的格式化</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ hadoop hdfs -format</div></pre></td></tr></table></figure>
<p>成功的话，会看到 “successfully formatted” 和 “Exitting with status 0” 的提示，若为 “Exitting with status 1” 则是出错。</p>
<h3 id="开启-NameNode-、DataNode-守护进程-和YARN"><a href="#开启-NameNode-、DataNode-守护进程-和YARN" class="headerlink" title="开启 NameNode 、DataNode 守护进程 和YARN"></a>开启 NameNode 、DataNode 守护进程 和YARN</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ start-dfs.sh</div><div class="line">$ start-yarn.sh</div></pre></td></tr></table></figure>
<p>通过jps 来判断是否成功启动<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 root]$ jps</div><div class="line">8195 NodeManager</div><div class="line">8106 ResourceManager</div><div class="line">7707 NameNode</div><div class="line">7821 DataNode</div><div class="line">7965 SecondaryNameNode</div><div class="line">10382 Jps</div></pre></td></tr></table></figure></p>
<p>若成功启动则会列出如下进程:  NameNode 、DataNode、SecondaryNameNode、NodeManager、ResourceManager</p>
<h2 id="安装Hbase"><a href="#安装Hbase" class="headerlink" title="安装Hbase"></a><strong>安装Hbase</strong></h2><h3 id="下载hbase-1-2-3-bin-tar-gz包"><a href="#下载hbase-1-2-3-bin-tar-gz包" class="headerlink" title="下载hbase-1.2.3-bin.tar.gz包"></a>下载hbase-1.2.3-bin.tar.gz包</h3><p>下载的hbase版本需要与安装的hadoop匹配，具体参考下面的链接<br><a href="https://hbase.apache.org/book.html#configuration" target="_blank" rel="external">hbase-config</a></p>
<h3 id="解压并修改文件权限-1"><a href="#解压并修改文件权限-1" class="headerlink" title="解压并修改文件权限"></a>解压并修改文件权限</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ tar -zxvf hbase-1.2.3-bin.tar.gz -C /usr/local/    # 解压到/usr/local中</div><div class="line">$ cd /usr/local/</div><div class="line">$ sudo ln -s hbase-1.2.3 hbase</div><div class="line">$ sudo chown -R hadoop:hadoop ./hbase        # 修改文件权限</div></pre></td></tr></table></figure>
<h3 id="配置环境变量-1"><a href="#配置环境变量-1" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">$ sudo vim /etc/profile</div></pre></td></tr></table></figure>
<p>添加如下内容<br><figure class="highlight vim"><table><tr><td class="code"><pre><div class="line">#hbase Env</div><div class="line">export HBASE_HOME=/usr/local/hbase</div><div class="line">export PATH=$PATH:$HBASE_HOME/bin</div></pre></td></tr></table></figure></p>
<h3 id="测试hadoop是否可用-1"><a href="#测试hadoop是否可用-1" class="headerlink" title="测试hadoop是否可用"></a>测试hadoop是否可用</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 root]$ hbase version</div><div class="line">HBase 1.2.3</div><div class="line">Source code repository git://kalashnikov.att.net/Users/stack/checkouts/hbase.git.commit revision=bd63744624a26dc3350137b564fe746df7a721a4</div><div class="line">Compiled by stack on Mon Aug 29 15:13:42 PDT 2016</div><div class="line">From source with checksum 0ca49367ef6c3a680888bbc4f1485d18</div></pre></td></tr></table></figure>
<p>成功则会显示如上的Hbase版本信息</p>
<h3 id="HBase伪分布式模式"><a href="#HBase伪分布式模式" class="headerlink" title="HBase伪分布式模式"></a>HBase伪分布式模式</h3><h4 id="修改配置文件-1"><a href="#修改配置文件-1" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><ul>
<li><p>修改hbase-env.sh<br>添加变量HBASE_CLASSPATH，并将路径设置为本机Hadoop安装目录下的conf目录（即{HADOOP_HOME}/conf）</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><div class="line">export JAVA_HOME=/usr/local/jdk-<span class="number">1.8</span>.<span class="number">0</span>_45</div><div class="line">export HBASE_CLASSPATH=/usr/hadoop/<span class="keyword">conf</span> </div><div class="line">export HBASE_MANAGES_ZK=true</div></pre></td></tr></table></figure>
</li>
<li><p>修改hbase-site.xml<br>修改hbase.rootdir，将其指向localhost(与hdfs的端口保持一致)，并指定HBase在HDFS上的存储路径。将属性hbase.cluter.distributed设置为true。假设当前Hadoop集群运行在伪分布式模式下，且NameNode运行在9000端口；</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><div class="line"><span class="symbol">&lt;configuration&gt;</span></div><div class="line">    <span class="symbol">&lt;property&gt;</span></div><div class="line">        <span class="symbol">&lt;name&gt;</span>hbase.rootdir&lt;/name&gt;</div><div class="line">        <span class="symbol">&lt;value&gt;</span>hdf<span class="variable">s:</span>//localhos<span class="variable">t:9000</span>/hbase&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    <span class="symbol">&lt;property&gt;</span></div><div class="line">        <span class="symbol">&lt;name&gt;</span>hbase.cluster.distributed&lt;/name&gt;</div><div class="line">        <span class="symbol">&lt;value&gt;</span>true&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h3><p>完成以上操作后启动HBase，启动顺序：先启动Hadoop–&gt;再启动HBase，关闭顺序：先关闭HBase–&gt;再关闭Hadoop。<br>假设hadoop已经启动。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 hbase]$ start-hbase.sh</div><div class="line">localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-hadoop-zookeeper-osd01.out</div><div class="line">starting master, logging to /usr/local/hbase/logs/hbase-hadoop-master-osd01.out</div><div class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0</div><div class="line">Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0</div><div class="line">starting regionserver, logging to /usr/local/hbase/logs/hbase-hadoop-1-regionserver-osd01.out</div><div class="line">[hadoop@osd01 hbase]$ jps</div><div class="line">23189 SecondaryNameNode</div><div class="line">28139 HQuorumPeer</div><div class="line">22908 NameNode</div><div class="line">23005 DataNode</div><div class="line">23341 ResourceManager</div><div class="line">28205 HMaster</div><div class="line">28333 HRegionServer</div><div class="line">23438 NodeManager</div><div class="line">28815 Jps</div></pre></td></tr></table></figure></p>
<h3 id="进入shell模式"><a href="#进入shell模式" class="headerlink" title="进入shell模式"></a>进入shell模式</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 hbase]$ hbase shell</div><div class="line">2016-10-31 11:07:31,779 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">SLF4J: Class path contains multiple SLF4J bindings.</div><div class="line">SLF4J: Found binding in [jar:file:/usr/local/hbase-1.2.3/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</div><div class="line">SLF4J: Found binding in [jar:file:/usr/local/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</div><div class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</div><div class="line">SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</div><div class="line">HBase Shell; enter &apos;help&lt;RETURN&gt;&apos; for list of supported commands.</div><div class="line">Type &quot;exit&lt;RETURN&gt;&quot; to leave the HBase Shell</div><div class="line">Version 1.2.3, rbd63744624a26dc3350137b564fe746df7a721a4, Mon Aug 29 15:13:42 PDT 2016</div><div class="line"></div><div class="line">hbase(main):001:0&gt;</div></pre></td></tr></table></figure>
<h3 id="查看HDFS的HBase数据库文件"><a href="#查看HDFS的HBase数据库文件" class="headerlink" title="查看HDFS的HBase数据库文件"></a>查看HDFS的HBase数据库文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">[hadoop@osd01 hbase]$ hadoop fs -ls /hbase</div><div class="line">16/10/31 11:08:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">Found 7 items</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2016-10-31 11:06 /hbase/.tmp</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2016-10-31 11:06 /hbase/MasterProcWALs</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2016-10-31 11:06 /hbase/WALs</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2016-10-31 10:36 /hbase/data</div><div class="line">-rw-r--r--   1 hadoop supergroup         42 2016-10-31 10:35 /hbase/hbase.id</div><div class="line">-rw-r--r--   1 hadoop supergroup          7 2016-10-31 10:35 /hbase/hbase.version</div><div class="line">drwxr-xr-x   - hadoop supergroup          0 2016-10-31 11:06 /hbase/oldWALs</div></pre></td></tr></table></figure>
<h2 id="hive-安装"><a href="#hive-安装" class="headerlink" title="hive 安装"></a><strong>hive 安装</strong></h2><hr>
<p><a href="http://www.powerxing.com/install-hadoop-in-centos/" target="_blank" rel="external">参考链接1</a><br><a href="http://blog.csdn.net/andie_guo/article/details/44086389" target="_blank" rel="external">参考链接2</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;centos7 + hadoop2.7.2 + jdk1.8 + hbase1.2.3&lt;/p&gt;
&lt;h2 i
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="hbase" scheme="http://yoursite.com/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>Java 反射机制</title>
    <link href="http://yoursite.com/2016/10/27/Java%20%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/"/>
    <id>http://yoursite.com/2016/10/27/Java 反射机制/</id>
    <published>2016-10-27T07:39:49.000Z</published>
    <updated>2017-02-17T02:10:12.176Z</updated>
    
    <content type="html"><![CDATA[<p>JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。<br>Java反射机制主要提供了以下功能： 在运行时判断任意一个对象所属的类；在运行时构造任意一个类的对象；在运行时判断任意一个类所具有的成员变量和方法；在运行时调用任意一个对象的方法；生成动态代理…</p>
<h2 id="得到某个对象属性"><a href="#得到某个对象属性" class="headerlink" title="得到某个对象属性"></a><strong>得到某个对象属性</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getProperty</span><span class="params">(Object owner, String fieldName)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">       Class ownerClass = owner.getClass();</div><div class="line">       Field field = ownerClass.getField(fieldName);<span class="comment">// 属性必须是public，否则会报java.lang.NoSuchFieldException异常</span></div><div class="line">       Object property = field.get(owner);</div><div class="line">       <span class="keyword">return</span> property;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<h2 id="得到某个类的静态属性"><a href="#得到某个类的静态属性" class="headerlink" title="得到某个类的静态属性"></a><strong>得到某个类的静态属性</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">getStaticProperty</span><span class="params">(String className, String fieldName)</span></span></div><div class="line">        <span class="keyword">throws</span> Exception &#123;</div><div class="line">    Class ownerClass = Class.forName(className);</div><div class="line">    Field field = ownerClass.getField(fieldName);</div><div class="line">    Object property = field.get(ownerClass); <span class="comment">//因为该属性是静态的，所以直接从类的Class里取。</span></div><div class="line">    <span class="keyword">return</span> property;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="执行某对象的方法"><a href="#执行某对象的方法" class="headerlink" title="执行某对象的方法"></a><strong>执行某对象的方法</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">invokeMethod</span><span class="params">(Object owner, String methodName, Object[] args)</span></span></div><div class="line">        <span class="keyword">throws</span> Exception &#123;</div><div class="line">    Class ownerClass = owner.getClass();</div><div class="line">    Class[] argsClass = <span class="keyword">new</span> Class[args.length];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = args.length; i &lt; j; i++) &#123;</div><div class="line">        argsClass[i] = args[i].getClass();</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// 通过methodName和参数的argsClass（方法中的参数类型集合）数组得到要执行的Method。</span></div><div class="line">    Method method = ownerClass.getMethod(methodName, argsClass);</div><div class="line">    <span class="comment">// 执行该Method.invoke方法的参数是执行这个方法的对象owner，和参数数组args，</span></div><div class="line">    <span class="comment">// 可以这么理解：owner对象中带有参数args的method方法。返回值是Object，也既是该方法的返回值。</span></div><div class="line">    <span class="keyword">return</span> method.invoke(owner, args);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="执行某个类的静态方法"><a href="#执行某个类的静态方法" class="headerlink" title="执行某个类的静态方法"></a><strong>执行某个类的静态方法</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title">invokeStaticMethod</span><span class="params">(Object owner, String methodName, Object[] args)</span></span></div><div class="line">        <span class="keyword">throws</span> Exception &#123;</div><div class="line">    Class ownerClass = owner.getClass();</div><div class="line">    Class[] argsClass = <span class="keyword">new</span> Class[args.length];</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = args.length; i &lt; j; i++) &#123;</div><div class="line">        argsClass[i] = args[i].getClass();</div><div class="line">    &#125;</div><div class="line">    Method method = ownerClass.getMethod(methodName,argsClass);</div><div class="line">    <span class="comment">// 基本的原理和第3点相同，不同点是最后一行，invoke的一个参数是null，因为这是静态方法，不需要借助实例运行。</span></div><div class="line">    <span class="keyword">return</span> method.invoke(<span class="keyword">null</span>,args);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="判断是否为某个类的实例"><a href="#判断是否为某个类的实例" class="headerlink" title="判断是否为某个类的实例"></a><strong>判断是否为某个类的实例</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isInstance</span><span class="params">(Object obj, Class cls)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> cls.isInstance(obj);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Method-invoke"><a href="#Method-invoke" class="headerlink" title="Method.invoke"></a><strong>Method.invoke</strong></h2><figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="keyword">import</span> java.lang.reflect.Method;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InvokeTest</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> sum;</div><div class="line">    String msg;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> param1, <span class="keyword">int</span> param2)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> param1 + param2;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">echo</span><span class="params">(String msg)</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"echo "</span> + msg;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getSum</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> sum;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSum</span><span class="params">(<span class="keyword">int</span> sum)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.sum = sum;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMsg</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> msg;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setMsg</span><span class="params">(String msg)</span> </span>&#123;</div><div class="line">        <span class="keyword">this</span>.msg = msg;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">        Class&lt;InvokeTest&gt; classType = InvokeTest.class;</div><div class="line">        InvokeTest invokerTester = classType.newInstance();</div><div class="line"></div><div class="line">        Method addMethod = classType.getMethod(<span class="string">"add"</span>, <span class="keyword">int</span>.class,</div><div class="line">                <span class="keyword">int</span>.class);</div><div class="line">        <span class="comment">// Method类的invoke(Object obj,Object args[])方法接收的参数必须为对象，</span></div><div class="line">        <span class="comment">// 如果参数为基本类型数据，必须转换为相应的包装类型的对象。invoke()方法的返回值总是对象，</span></div><div class="line">        <span class="comment">// 如果实际被调用的方法的返回类型是基本类型数据，那么invoke()方法会把它转换为相应的包装类型的对象，再将其返回</span></div><div class="line">        Object result = addMethod.invoke(invokerTester, <span class="number">100</span>, <span class="number">200</span>);</div><div class="line">        System.out.println(result);</div><div class="line"></div><div class="line">        Method echoMethod = classType.getMethod(<span class="string">"echo"</span>, String.class);</div><div class="line">        result = echoMethod.invoke(invokerTester, <span class="string">"hello"</span>);</div><div class="line">        System.out.println(result);</div><div class="line"></div><div class="line">        Method setSumMethod = classType.getMethod(<span class="string">"setSum"</span>, <span class="keyword">int</span>.class);</div><div class="line">        setSumMethod.invoke(invokerTester, <span class="number">12</span>);</div><div class="line">        System.out.println(invokerTester.getSum());</div><div class="line"></div><div class="line">        Method setMsgMethod = classType.getMethod(<span class="string">"setMsg"</span>, String.class);</div><div class="line">        setMsgMethod.invoke(invokerTester, <span class="string">"Hello world!"</span>);</div><div class="line">        System.out.println(invokerTester.getMsg());</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><a href="http://azrael6619.iteye.com/blog/429797" target="_blank" rel="external">参考链接</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。&lt;br&gt;Java反射机制主要提供了以下功能： 在运行时判断任意一个对象所
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="反射" scheme="http://yoursite.com/tags/%E5%8F%8D%E5%B0%84/"/>
    
  </entry>
  
  <entry>
    <title>Linux 磁盘管理</title>
    <link href="http://yoursite.com/2016/10/26/Linux-%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2016/10/26/Linux-磁盘管理/</id>
    <published>2016-10-26T08:07:42.000Z</published>
    <updated>2017-02-17T02:10:12.187Z</updated>
    
    <content type="html"><![CDATA[<p>Linux磁盘管理常用的命令：<strong>df</strong>、<strong>du</strong>、<strong>fdisk</strong>.</p>
<h2 id="df"><a href="#df" class="headerlink" title="df"></a>df</h2><p>df命令可以获取硬盘被占用了多少空间，目前还剩下多少空间等信息，它也可以显示所有文件系统对i节点和磁盘块的使用情况。<br>df命令各个选项的含义如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">-a：显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统，如/proc文件系统。</div><div class="line">-k：以k字节为单位显示。</div><div class="line">-i：显示i节点信息，而不是磁盘块。</div><div class="line">-t：显示各指定类型的文件系统的磁盘空间使用情况。</div><div class="line">-x：列出不是某一指定类型文件系统的磁盘空间使用情况（与t选项相反）。</div><div class="line">-T：显示文件系统类型。</div></pre></td></tr></table></figure></p>
<h2 id="du"><a href="#du" class="headerlink" title="du"></a>du</h2><p>du的英文原义为“disk usage”，含义为显示磁盘空间的使用情况，统计目录（或文件）所占磁盘空间的大小。该命令的功能是逐级进入指定目录的每一个子目录并显示该目录占用文件系统数据块（1024字节）的情况。若没有给出指定目录，则对当前目录进行统计。<br>df命令的各个选项含义如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">-s：对每个Names参数只给出占用的数据块总数。</div><div class="line">-a：递归地显示指定目录中各文件及子目录中各文件占用的数据块数。若既不指定-s，也不指定-a，则只显示Names中的每一个目录及其中的各子目录所占的磁盘块数。</div><div class="line">-b：以字节为单位列出磁盘空间使用情况（系统默认以k字节为单位）。</div><div class="line">-k：以<span class="number">1024</span>字节为单位列出磁盘空间使用情况。</div><div class="line">-c：最后再加上一个总计（系统默认设置）。</div><div class="line">-l：计算所有的文件大小，对硬链接文件，则计算多次。</div><div class="line">-x：跳过在不同文件系统上的目录不予统计。</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">//列出各文件系统的磁盘空间使用情况</div><div class="line">#df</div><div class="line">Filesystem           1k-blocks      Used   Available Use% Mounted on</div><div class="line">/dev/hda5               381139     332921     28540  93% /</div><div class="line">/dev/hda1                46636      6871     37357  16% /boot</div><div class="line">/dev/hda3             10041144   6632528   2898556  70% /home</div><div class="line">none                    127372         0    127372   0% /dev/shm</div><div class="line">/dev/hda2             27474876  24130460   1948772  93% /usr</div><div class="line">/dev/hda6               256667    232729     10686  96% /var</div></pre></td></tr></table></figure>
<p>第1列是代表文件系统对应的设备文件的路径名（一般是硬盘上的分区）；第2列给出分区包含的数据块（1024字节）的数目；第3，4列分别表示已用的和可用的数据块数目。<br>用户也许会感到奇怪，第3，4列块数之和不等于第2列中的块数。这是因为默认的每个分区都留了少量空间供系统管理员使用的缘故。即使遇到普通用户空间已满的情况，管理员仍能登录和留有解决问题所需的工作空间。清单中Use%列表示普通用户空间使用的百分比，若这一数字达到100%，分区仍然留有系统管理员使用的空间。<br>最后，Mounted on列表示文件系统的安装点。</p>
<h2 id="fisk"><a href="#fisk" class="headerlink" title="fisk"></a>fisk</h2><p>fdisk可以划分磁盘分区。下面给出使用Fdisk命令进行磁盘分区的操作步骤。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Linux磁盘管理常用的命令：&lt;strong&gt;df&lt;/strong&gt;、&lt;strong&gt;du&lt;/strong&gt;、&lt;strong&gt;fdisk&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&quot;df&quot;&gt;&lt;a href=&quot;#df&quot; class=&quot;headerlink&quot; title=&quot;df
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="磁盘" scheme="http://yoursite.com/tags/%E7%A3%81%E7%9B%98/"/>
    
  </entry>
  
  <entry>
    <title>JVM原理</title>
    <link href="http://yoursite.com/2016/10/25/JVM%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/2016/10/25/JVM原理/</id>
    <published>2016-10-25T09:15:18.000Z</published>
    <updated>2017-02-17T02:10:12.160Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JVM-原理"><a href="#JVM-原理" class="headerlink" title="JVM 原理"></a>JVM 原理</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Java编译器和OS平台之间的虚拟处理器。它是一种利用软件方法实现的抽象的计算机基于下层的操作系统和硬件平台，可以在上面执行java的字节码程序。</p>
<p>java编译器只要面向JVM，生成JVM能理解的代码或字节码文件。Java源文件经编译成字节码程序，通过JVM将每一条指令翻译成不同平台机器码，通过特定平台运行。</p>
<h3 id="JAVA运行过程"><a href="#JAVA运行过程" class="headerlink" title="JAVA运行过程"></a>JAVA运行过程</h3><p>Java语言写的源程序通过Java编译器，编译成与平台无关的‘字节码程序’(.class文件，也就是0，1二进制程序)，然后在OS之上的Java解释器中解释执行。</p>
<p><img src="http://oflrm5g9z.bkt.clouddn.com/16-10-25/87103552.jpg" alt="java运行过程"></p>
<h3 id="JVM执行过程"><a href="#JVM执行过程" class="headerlink" title="JVM执行过程"></a>JVM执行过程</h3><ul>
<li>加载 .class文件</li>
<li>管理并分配内存</li>
<li>执行垃圾收集</li>
</ul>
<p><img src="http://oflrm5g9z.bkt.clouddn.com/16-10-25/46394905.jpg" alt="jvm运行过程"></p>
<p>JRE/JDK（java运行时环境）由JVM构造JAVA运行程序</p>
<p><a href="http://www.codeceo.com/article/jvm-stack-heap.html" target="_blank" rel="external">参考链接</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;JVM-原理&quot;&gt;&lt;a href=&quot;#JVM-原理&quot; class=&quot;headerlink&quot; title=&quot;JVM 原理&quot;&gt;&lt;/a&gt;JVM 原理&lt;/h2&gt;&lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="jvm" scheme="http://yoursite.com/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>Spring MVC 框架及基本配置</title>
    <link href="http://yoursite.com/2016/07/21/Spring%20MVC%20%E6%A1%86%E6%9E%B6%E5%8F%8A%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2016/07/21/Spring MVC 框架及基本配置/</id>
    <published>2016-07-21T02:08:09.000Z</published>
    <updated>2017-02-17T02:10:12.223Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Web开发-请求响应模型"><a href="#Web开发-请求响应模型" class="headerlink" title="Web开发-请求响应模型"></a>Web开发-请求响应模型</h2><p><center><img src="http://oflrm5g9z.bkt.clouddn.com/17-2-15/6043565-file_1487163503878_11a8c.png" alt="请求响应模型"></center></p>
<ol>
<li>web客户端（如：浏览器）发起请求，如访问www.baidu.com</li>
<li>web服务器端（如：tomcat）接收请求，处理请求，最后产生响应</li>
<li>web服务器端处理完成后，返回内容给客户端，客户端对接收的内容进行处理（如web浏览器对接收到的html内容进行渲染展示）<h2 id="Web-MVC概述"><a href="#Web-MVC概述" class="headerlink" title="Web MVC概述"></a>Web MVC概述</h2><center><img src="http://oflrm5g9z.bkt.clouddn.com/17-2-15/28677677-file_1487163208601_13fe6.png" alt=" MVC概述"></center><br><strong>Model（模型）</strong>：数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或 JavaBean 组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据） 和 服务层（行为）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。<br><strong>View（视图）</strong>：负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。<br><strong>Controller（控制器）</strong>：接收用户请求，委托给模型进行处理（状态改变） ，处理完毕后把返回的模型数据返回给视图，由视图负责展示。 也就是说控制器做了个调度员的工作。<h2 id="Spring-MVC-架构"><a href="#Spring-MVC-架构" class="headerlink" title="Spring MVC 架构"></a>Spring MVC 架构</h2><h3 id="请求处理过程"><a href="#请求处理过程" class="headerlink" title="请求处理过程"></a>请求处理过程</h3><center><img src="http://oflrm5g9z.bkt.clouddn.com/17-2-15/89018877-file_1487163563329_16205.png" alt=" 请求处理过程"></center><br>执行步骤如下：</li>
<li>首先用户发送请求————&gt;前端控制器，前端控制器根据请求信息（如 URL）来决定选择哪一个页面控制器进行处理并把请求委托给它；上图中的 1、2 步骤；</li>
<li>页面控制器接收到请求后，进行功能处理，首先需要收集和绑定请求参数到一个对象，并进行验证，然后将该对象对象委托给业务对象进行处理；处理完毕后返回一个 ModelAndView（模型数据和逻辑视图名） ；上图中的 3、4、5 步骤；</li>
<li>前端控制器收回控制权，然后根据返回的逻辑视图名，选择相应的视图进行渲染，并把模型数据传入以便视图渲染；上图 中的步骤 6、7；</li>
<li>前端控制器再次收回控制权，将响应返回给用户，图 2-1 中的步骤 8；至此整个结束。<h3 id="核心架构"><a href="#核心架构" class="headerlink" title="核心架构"></a>核心架构</h3><center><img src="http://oflrm5g9z.bkt.clouddn.com/17-2-15/55267022-file_1487163626154_10138.png" alt=" 核心架构"></center><br>具体流程步骤：</li>
<li>首先用户发送请求——&gt;DispatcherServlet，前端控制器收到请求后自己不进行处理，而是委托给其他的解析器进行处理，作为统一访问点，进行全局的流程控制；</li>
<li>DispatcherServlet——&gt;Handlermapping（请求到处理器的映射），HandlerMapping 将会把请求映射为 HandlerExecutionChain 对象（包含一个 Handler 处理器（页面控制器）对象、多个 HandlerInterceptor 拦截器）对象，通过这种策略模式，很容易添加新的映射策略；</li>
<li>DispatcherServlet——&gt;HandlerAdapter，HandlerAdapter 将会把处理器包装为适配器，从而支持多种类型的处理器，即适配器设计模式的应用，从而很容易支持很多类型的处理器；</li>
<li>HandlerAdapter——&gt;处理器功能处理方法的调用，HandlerAdapter 将会根据适配的结果调用真正的处理器的功能处理方法，完成功能处理；并返回一个 ModelAndView 对象（包含模型数据、逻辑视图名）；</li>
<li>ModelAndView 的逻辑视图名——&gt; ViewResolver， ViewResolver 将把逻辑视图名解析为具体的 View，通过这种策略模式，很容易更换其他视图技术；</li>
<li>View——&gt;渲染，View 会根据传进来的 Model 模型数据进行渲染，此处的 Model 实际是一个 Map 数据结构，因此很容易支持其他视图技术；</li>
<li>返回控制权给 DispatcherServlet，由 DispatcherServlet 返回响应给用户，到此一个流程结束。<h2 id="入门（Hello）"><a href="#入门（Hello）" class="headerlink" title="入门（Hello）"></a>入门（Hello）</h2><h3 id="前端控制器（DispatcherServlet）配置"><a href="#前端控制器（DispatcherServlet）配置" class="headerlink" title="前端控制器（DispatcherServlet）配置"></a>前端控制器（DispatcherServlet）配置</h3>web.xml 配置<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!--前端控制器--&gt;</div><div class="line">&lt;servlet&gt;</div><div class="line">    &lt;servlet-name&gt;dispatcher&lt;/servlet-name&gt;</div><div class="line">    &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;</div><div class="line">    &lt;init-param&gt;</div><div class="line">        &lt;!--参数定义了要装入的 Spring 配置文件。--&gt;</div><div class="line">        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;</div><div class="line">        &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt;</div><div class="line">    &lt;/init-param&gt;</div><div class="line">    &lt;!--</div><div class="line">        当值为0或者大于0时，表示容器在应用启动时就加载这个servlet；</div><div class="line">        当是一个负数时或者没有指定时，则指示容器在该servlet被选择时才加载。</div><div class="line">        正数的值越小，启动该servlet的优先级越高。</div><div class="line">    --&gt;</div><div class="line">    &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;</div><div class="line">&lt;/servlet&gt;</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="handlerMapping、handlerAdapter配置"><a href="#handlerMapping、handlerAdapter配置" class="headerlink" title="handlerMapping、handlerAdapter配置"></a>handlerMapping、handlerAdapter配置</h3><p>resources/spring-mvc.xml中配置handlerMapping、handlerAdapter<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 非注解式控制器 --&gt;</div><div class="line">    &lt;!-- 处理器映射解析器HandlerMapping --&gt;</div><div class="line">    &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot;/&gt;</div><div class="line">    &lt;!-- 处理器适配器 --&gt;</div><div class="line">    &lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt;</div><div class="line">    &lt;!-- 处理器 --&gt;</div><div class="line">    &lt;bean name=&quot;/hello&quot; class=&quot;com.zfy.demo.springmvc.controller.HelloController&quot;/&gt;</div><div class="line"></div><div class="line"></div><div class="line">    &lt;!-- 注解式控制器 --&gt;</div><div class="line">    &lt;!-- 开启注解式处理器支持(启用注解) 方式1 --&gt;</div><div class="line">    &lt;!--bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping&quot;/&gt;--&gt;</div><div class="line">    &lt;!--&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;/&gt;--&gt;</div><div class="line">    &lt;!-- 开启注解式处理器支持(启用注解) 方式2 --&gt;</div><div class="line">    &lt;!--&lt;mvc:annotation-driven /&gt;--&gt;</div></pre></td></tr></table></figure></p>
<h3 id="viewResolver"><a href="#viewResolver" class="headerlink" title="viewResolver"></a>viewResolver</h3><p>resources/spring-mvc.xml中配置viewResolver<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 视图分解器 --&gt;</div><div class="line">&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt;</div><div class="line">    &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt;</div><div class="line">    &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt;</div><div class="line">    &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;</div><div class="line">&lt;/bean&gt;</div></pre></td></tr></table></figure></p>
<h3 id="开发处理器-页面处理器"><a href="#开发处理器-页面处理器" class="headerlink" title="开发处理器/页面处理器"></a>开发处理器/页面处理器</h3><p>非注解式controller<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class HelloController implements Controller &#123;</div><div class="line"></div><div class="line">    public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123;</div><div class="line">        //1、收集参数</div><div class="line">        //2、绑定参数到命令对象</div><div class="line">        //3、调用业务对象</div><div class="line">        //4、选择下一个页面</div><div class="line">        ModelAndView mv = new ModelAndView();</div><div class="line">        //添加模型数据 可以是任意的POJO对象</div><div class="line">        mv.addObject(&quot;message&quot;, &quot;Hello World!&quot;);</div><div class="line">        //设置逻辑视图名，视图解析器会根据该名字解析到具体的视图页面</div><div class="line">        mv.setViewName(&quot;/hello&quot;);</div><div class="line">        return mv;</div><div class="line">    &#125;</div></pre></td></tr></table></figure></p>
<p> <strong>ModelAndView</strong>：包含了视图要实现的模型数据和逻辑视图名；“mv.addObject(“message”, “Hello World!”);”表示添加模型数据，此处可以是任意 POJO 对象；“mv.setViewName(“/hello”);”表示设置逻辑视图名为“hello”，视图解析器会将其解析为具体的视图，如前边的视图解析器InternalResourceVi。wResolver 会将其解析为“WEB-INF/jsp/hello.jsp”。<br>注解式controller<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">@Controller</div><div class="line">public class HelloController2 &#123;</div><div class="line">    @RequestMapping(value = &quot;/hello2&quot;)</div><div class="line">    public ModelAndView hello(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) &#123;</div><div class="line">        Map&lt;String, Object&gt; data = new HashMap&lt;&gt;();</div><div class="line">        data.put(&quot;message&quot;, &quot;hello world 2&quot;);</div><div class="line">        return new ModelAndView(&quot;/hello&quot;, data);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="开发视图页面"><a href="#开发视图页面" class="headerlink" title="开发视图页面"></a>开发视图页面</h3><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; %&gt;</div><div class="line">&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;</div><div class="line">&lt;html&gt;</div><div class="line">&lt;head&gt;</div><div class="line">    &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;</div><div class="line">    &lt;title&gt;Hello World&lt;/title&gt;</div><div class="line">&lt;/head&gt;</div><div class="line">&lt;body&gt;</div><div class="line">$&#123;message&#125;</div><div class="line">&lt;/body&gt;</div><div class="line">&lt;/html&gt;</div></pre></td></tr></table></figure>
<h3 id="运行流程分析"><a href="#运行流程分析" class="headerlink" title="运行流程分析"></a>运行流程分析</h3><p><center><img src="http://oflrm5g9z.bkt.clouddn.com/17-2-15/53622352-file_1487163689720_8c8.png" alt=" 运行流程分析"></center><br>运行步骤如下：</p>
<ol>
<li>首先用户发送请求 <a href="http://localhost:8080/hello——&gt;web" target="_blank" rel="external">http://localhost:8080/hello——&gt;web</a> 容器，web 容器根据“/hello”路径映射到DispatcherServlet（url-pattern 为/）进行处理；</li>
<li>DispatcherServlet——&gt;BeanNameUrlHandlerMapping 进行请求到处理的映射，BeanNameUrlHandlerMapping 将“/hello”路径直接映射到名字为“/hello”的 Bean 进行处理，即 HelloWorldController，BeanNameUrlHandlerMapping将其包装为HandlerExecutionChain（只包括 HelloWorldController 处理器，没有拦截器） ；</li>
<li>DispatcherServlet——&gt; SimpleControllerHandlerAdapter，SimpleControllerHandlerAdapter 将 HandlerExecutionChain中的处理器（HelloWorldController）适配为 SimpleControllerHandlerAdapter；</li>
<li>SimpleControllerHandlerAdapter — — &gt; HelloWorldController 处 理 器 功 能 处 理 方 法 的 调 用 ，SimpleControllerHandlerAdapter 将会调用处理器的 handleRequest 方法进行功能处理，该处理方法返回一个 ModelAndView 给 DispatcherServlet；</li>
<li>hello（ModelAndView 的逻辑视图名）——&gt;InternalResourceViewResolver， InternalResourceViewResolver 使用JstlView，具体视图页面在/WEB-INF/jsp/hello.jsp；</li>
<li>JstlView（/WEB-INF/jsp/hello.jsp）——&gt;渲染，将在处理器传入的模型数据(message=HelloWorld！)在视图中展示出来；</li>
<li>返回控制权给 DispatcherServlet，由 DispatcherServlet 返回响应给用户，到此一个流程结束。<h2 id="post中文乱码解决方案"><a href="#post中文乱码解决方案" class="headerlink" title="post中文乱码解决方案"></a>post中文乱码解决方案</h2>spring Web MVC 框架提供了 org.springframework.web.filter.CharacterEncodingFilter 用于解决 POST 方式造成的中文乱码问题，具体配置如下：<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">&lt;!-- 指定UTF-8编码 --&gt;</div><div class="line">&lt;filter&gt;</div><div class="line">    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;</div><div class="line">    &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt;</div><div class="line">    &lt;init-param&gt;</div><div class="line">        &lt;param-name&gt;encoding&lt;/param-name&gt;</div><div class="line">        &lt;param-value&gt;utf-8&lt;/param-value&gt;</div><div class="line">    &lt;/init-param&gt;</div><div class="line">&lt;/filter&gt;</div><div class="line">&lt;filter-mapping&gt;</div><div class="line">    &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt;</div><div class="line">    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;</div><div class="line">&lt;/filter-mapping&gt;</div></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Web开发-请求响应模型&quot;&gt;&lt;a href=&quot;#Web开发-请求响应模型&quot; class=&quot;headerlink&quot; title=&quot;Web开发-请求响应模型&quot;&gt;&lt;/a&gt;Web开发-请求响应模型&lt;/h2&gt;&lt;p&gt;&lt;center&gt;&lt;img src=&quot;http://oflrm
    
    </summary>
    
      <category term="spring" scheme="http://yoursite.com/categories/spring/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="spring" scheme="http://yoursite.com/tags/spring/"/>
    
      <category term="springmvc" scheme="http://yoursite.com/tags/springmvc/"/>
    
  </entry>
  
  <entry>
    <title>Java中Volatile关键字详解</title>
    <link href="http://yoursite.com/2016/07/21/Java%E4%B8%ADVolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2016/07/21/Java中Volatile关键字详解/</id>
    <published>2016-07-21T02:08:09.000Z</published>
    <updated>2017-02-17T02:48:10.629Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>可见性是一种复杂的属性，因为可见性中的错误总是会违背我们的直觉。通常，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。<br><strong>可见性，是指线程之间的可见性，一个线程修改的状态对另一个线程是可见的</strong>。也就是一个线程修改的结果。另一个线程马上就能看到。比如：用volatile修饰的变量，就会具有可见性。volatile修饰的变量不允许线程内部缓存和重排序，即直接修改内存。所以对其他线程是可见的。但是这里需要注意一个问题，volatile只能让被他修饰内容具有可见性，但不能保证它具有原子性。比如 volatile int a = 0；之后有一个操作 a++；这个变量a具有可见性，但是a++ 依然是一个非原子操作，也就是这个操作同样存在线程安全问题。</p>
<h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>　<strong>原子是世界上的最小单位，具有不可分割性</strong>。比如 a=0；（a非long和double类型） 这个操作是不可分割的，那么我们说这个操作时原子操作。再比如：a++； 这个操作实际是a = a + 1；是可分割的，所以他不是一个原子操作。非原子操作都会存在线程安全问题，需要我们使用同步技术（sychronized）来让它变成一个原子操作。一个操作是原子操作，那么我们称它具有原子性。java的concurrent包下提供了一些原子类，我们可以通过阅读API来了解这些原子类的用法。比如：AtomicInteger、AtomicLong、AtomicReference等。<br>下面一段代码在多线程环境下，将存在问题。<br><figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">public class NoVisibility &#123;</div><div class="line">    private static boolean ready;</div><div class="line">    private static int number;</div><div class="line">    private static class ReaderThread extends Thread &#123;</div><div class="line">        @Override</div><div class="line">        public void run() &#123;</div><div class="line">            while(!ready) &#123;</div><div class="line">                Thread.yield();</div><div class="line">            &#125;</div><div class="line">            System.out.println(number);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        new ReaderThread().start();</div><div class="line">        number = 42;</div><div class="line">        ready = true;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>NoVisibility可能会持续循环下去，因为读线程可能永远都看不到ready的值。甚至NoVisibility可能会输出0，因为读线程可能看到了写入ready的值，但却没有看到之后写入number的值，这种现象被称为“重排序</strong>”。只要在某个线程中无法检测到重排序情况（即使在其他线程中可以明显地看到该线程中的重排序），那么就无法确保线程中的操作将按照程序中指定的顺序来执行。当主线程首先写入number，然后在没有同步的情况下写入ready，那么读线程看到的顺序可能与写入的顺序完全相反。<br>在没有同步的情况下，编译器、处理器以及运行时等都可能对操作的执行顺序进行一些意想不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行春旭进行判断，无法得到正确的结论。<br>这个看上去像是一个失败的设计，但却能使JVM充分地利用现代多核处理器的强大性能。例如，在缺少同步的情况下，Java内存模型允许编译器对操作顺序进行重排序，并将数值缓存在寄存器中。此外，它还允许CPU对操作顺序进行重排序，并将数值缓存在处理器特定的缓存中。</p>
<h1 id="volatile-原理"><a href="#volatile-原理" class="headerlink" title="volatile 原理"></a>volatile 原理</h1><p>Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他线程。当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，<strong>因此不会将该变量上的操作与其他内存操作一起重排序</strong>。volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。<br><strong>在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步机制。</strong></p>
<p><center><img src="http://i1.piimg.com/567571/b9abf6981bbe1dc6.png" alt=""></center><br>当对非volatile变量进行读写的时候，每个线程先从内存拷贝变量到CPU缓存中。如果计算机有多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的CPU cache中。<br><strong>而声明变量是volatile的，JVM保证了每次读变量都从内存中读，跳过CPU cache这一步。</strong><br>当一个变量定义为volatile之后，将具备两种特性：</p>
<ol>
<li>保证此变量对所有的线程的可见性，这里的“可见性”，如本文开头所述，当一个线程修改了这个变量的值，新值对于其他线程是立即得知的。但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存（详见：Java内存模型）来完成。</li>
<li>禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）。</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;可见性&quot;&gt;&lt;a href=&quot;#可见性&quot; class=&quot;headerlink&quot; title=&quot;可见性&quot;&gt;&lt;/a&gt;可见
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="volatile" scheme="http://yoursite.com/tags/volatile/"/>
    
  </entry>
  
</feed>
